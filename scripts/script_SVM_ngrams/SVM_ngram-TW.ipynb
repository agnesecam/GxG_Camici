{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8862ff3d-4fff-43ca-b33d-3ba7d65cafc5",
   "metadata": {},
   "source": [
    "# Fase 2 - SVM con ngrams (in-genre classification)\n",
    "\n",
    "Sviluppare un classificatore basato su SVM lineari che prende in input una rappresentazione del testo basata su n-grammi di caratteri, parole e part-of-speech. Riportare i seguenti risultati:\n",
    "- testare diverse rappresentazioni del testo che variano rispetto alla lunghezza degli ngrammi utilizzati e/o rispetto al tipo di informazione utilizzata all’interno degli ngrammi (forme, lemmi, caratteri, part-of-speech) e valutare i diversi sistemi con un\n",
    "processo di 5-fold cross validation condotto sul training set;\n",
    "- valutazione sul test set ufficiale del miglior sistema rispetto ai risultati ottenuti con il processo di 5-fold cross validation del punto sopra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc9019-629f-4dd9-8fb4-cff6b892d29d",
   "metadata": {},
   "source": [
    "Dal task GxG Evalita 2018:\n",
    "\n",
    "\"Given a (collection of) text(s) from a specific genre, the gender of the author has to be predicted. The task is cast as a binary classification task, with gender represented as F (female) or M (male). Gender prediction will be done in two ways: \n",
    "\n",
    "1. **using a model which has been trained on the same genre**\n",
    "2. using a model which has been trained on anything but that genre.\"\n",
    "\n",
    "In questo file utilizzeremo un modello allenato sullo stesso genere su cui poi verrà testato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1da0c7a-2576-4f36-a412-3dc51a422ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazioni necessarie\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74cfdf7-ab7f-476d-88e6-8e5f1c7cca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i documenti e le annotazioni\n",
    "conllu_dir = \"../../data/profiling_output/twitter/linguistic_annotation/twitter/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850ddcf9-5548-4d82-9425-85b685e8b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle classi per la gestione dei documenti\n",
    "class Document:\n",
    "    \"\"\"Classe per rappresentare un documento con le sue frasi e metadati.\"\"\"\n",
    "    def __init__(self, document_path):\n",
    "        self.document_path = document_path\n",
    "        self._parse_doc_info(document_path)\n",
    "        self.sentences = []\n",
    "        self.features = None\n",
    "    \n",
    "    \"\"\" Estrae informazioni dal nome del file .conllu. \"\"\"\n",
    "    def _parse_doc_info(self, document_path):\n",
    "        document_path = document_path.split('/')[-1]\n",
    "        document_info = document_path.split('.')[0].split('#')\n",
    "        self.split = document_info[0]\n",
    "        self.doc_id = document_info[1]\n",
    "        self.genre = document_info[2]\n",
    "        self.gender = document_info[3]\n",
    "\n",
    "    \"\"\" Aggiunge un oggetto Sentence alla lista self.sentences. \"\"\"\n",
    "    def add_sentence(self, sentence):\n",
    "        self.sentences.append(sentence)\n",
    "    \n",
    "    # Per dopo\n",
    "    \"\"\" Conta il totale dei token nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_tokens(self):\n",
    "        num_words = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_words += sentence.get_num_tokens()\n",
    "        return num_words\n",
    "\n",
    "    \"\"\" Conta il totale dei caratteri nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_chars += sentence.get_num_chars()\n",
    "        return num_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298f3db4-3391-4dd5-8fc1-bca24990b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self):\n",
    "        self.tokens = [] # Inizializza una Sentence (frase) vuota con self.tokens = [] che conterrà i token della frase\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        self.tokens.append(token) # Aggiunge un oggetto tokens\n",
    "    \n",
    "    def get_words(self):\n",
    "        return [token.word for token in self.tokens] # Restituisce una lista delle parole nella frase\n",
    "    \n",
    "    def get_lemmas(self):\n",
    "        return [token.lemma for token in self.tokens] # Restituisce una lista dei lemmi della frase\n",
    "    \n",
    "    def get_pos(self):\n",
    "        return [token.pos for token in self.tokens] # Restituisce una lista dei PoS-tag della frase\n",
    "    \n",
    "    def get_num_tokens(self): \n",
    "        return len(self.tokens) # Restituisce il numero di token nella frase \n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for token in self.tokens:\n",
    "            num_chars += token.get_num_chars()\n",
    "        num_chars += self.get_num_tokens() - 1 # Contiamo anche gli spazi\n",
    "        return num_chars\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ' '.join([token.word for token in self.tokens])\n",
    "        # Converte l'oggetto Sentence in una stringa leggibile, restituendo la frase completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3896e861-16c0-4956-b070-e7e14997d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, word, lemma, pos):\n",
    "        self.word = word\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        return len(self.word) # Restituisce il numero di caratteri della parola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dce69b-6975-462f-b294-cb95e644a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare le frasi di un documento\n",
    "def load_document_sentences(document):\n",
    "    sentence = Sentence()\n",
    "    for line in open(document.document_path, 'r', encoding='MacRoman'):\n",
    "        if line[0].isdigit(): # se la riga inizia con un numero, che in .conllu indica un token (se la riga non inizia con un numero vuol dire che contiene info extra, come ad esempio # text = o # sent_id\n",
    "            splitted_line = line.strip().split('\\t') # rimuove spazi e divide la riga in colonne usando \\t\n",
    "            # esempio di riga divisa in colonne splitted_line = ['1', 'dobbiamo', 'dovere', 'AUX', 'VM', ...]\n",
    "            \n",
    "            if '-' not in splitted_line[0]:  # se l'id della parola non contiene un trattino\n",
    "                # Esclude le preposizioni articolate (multitoken: della, negli, sul) che in .conllu sono scritte con -.\n",
    "                \n",
    "                token = Token(splitted_line[1], splitted_line[2], splitted_line[3])\n",
    "                '''\n",
    "                Crea un oggetto Token(word, lemma, pos) con:\n",
    "                    splitted_line[1] → Parola (dobbiamo)\n",
    "                    splitted_line[2] → Lemma (dovere) \n",
    "                    splitted_line[3] → PoS (parte del discorso) (AUX)\n",
    "                '''\n",
    "                sentence.add_token(token) # aggiungo il token alla frase corrente\n",
    "        if line == '\\n': # se la riga è vuota significa che la frase è finita, perché nel file conllu le frasi sono separate da righe vuote\n",
    "            document.add_sentence(sentence)\n",
    "            sentence = Sentence() # crea un nuovo oggetto per iniziare una nuova frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade83184-3a79-4382-859c-2886d6b787c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i file .conllu\n",
    "all_documents = []\n",
    "for file_name in os.listdir(conllu_dir):\n",
    "    file_path = os.path.join(conllu_dir, file_name)\n",
    "    if os.path.isfile(file_path): \n",
    "        document = Document(file_path)\n",
    "        load_document_sentences(document)\n",
    "        all_documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f86863-0754-4530-939f-23b71a5924a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da una frase\n",
    "def extract_word_ngrams_from_sentence(word_ngrams, sentence, el, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    if el == 'word':\n",
    "        all_words = sentence.get_words()\n",
    "    elif el == 'lemma':\n",
    "        all_words = sentence.get_lemmas()\n",
    "    elif el == 'pos':\n",
    "        all_words = sentence.get_pos()\n",
    "    else:\n",
    "        raise Exception(f'Invalid element {el}')\n",
    "\n",
    "    # scorriamo la lista delle parole ed estraiamo gli n-grammi\n",
    "    for i in range(0, len(all_words) - n + 1):  # -n+1 serve per non uscire dal vettore\n",
    "        ngram_words = all_words[i: i + n]\n",
    "        ngram = f'{el.upper()}_{n}_' + '_'.join(ngram_words)\n",
    "        if ngram not in word_ngrams:\n",
    "            word_ngrams[ngram] = 1\n",
    "        else:\n",
    "            word_ngrams[ngram] += 1\n",
    "    \n",
    "    return word_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869a8592-421d-4293-87ae-74d7521491b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_char_ngrams_from_sentence(char_ngrams, sentence, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    all_words = sentence.get_words()\n",
    "\n",
    "    # creiamo una stringa che contenga tutte le parole separate tra spazi perché vogliamo scorrere i caratteri\n",
    "    all_words = ' '.join(all_words)\n",
    "    \n",
    "    # scorriamo la stringa ed estraiamo gli n-grammi di caratteri\n",
    "    for i in range(0, len(all_words) - n + 1):\n",
    "        ngram_chars = all_words[i:i + n]\n",
    "        ngram = f'CHAR_{n}_' + ngram_chars\n",
    "\n",
    "        if ngram not in char_ngrams:\n",
    "            char_ngrams[ngram] = 1\n",
    "        else:\n",
    "            char_ngrams[ngram] += 1\n",
    "    \n",
    "    return char_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd39197-5701-40ea-8d1a-49079bd91ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da tutti i documenti\n",
    "def extract_documents_ngrams_normalized(all_documents, ngram_type='word', ngram_length=1):\n",
    "    for document in all_documents:\n",
    "        ngrams_dict = dict()\n",
    "        for sentence in document.sentences:\n",
    "            if ngram_type == 'word':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'word', ngram_length)\n",
    "            elif ngram_type == 'lemma':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'lemma', ngram_length)\n",
    "            elif ngram_type == 'pos':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'pos', ngram_length)\n",
    "            elif ngram_type == 'char':\n",
    "                extract_char_ngrams_from_sentence(ngrams_dict, sentence, ngram_length)\n",
    "        \n",
    "        num_words = document.get_num_tokens()\n",
    "        num_chars = document.get_num_chars()\n",
    "        normalize_ngrams(ngrams_dict, num_words if ngram_type != 'char' else num_chars)\n",
    "        \n",
    "        document.features = ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f56b040-9f01-4343-871e-6ef10ecdb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per normalizzare le feature\n",
    "def normalize_ngrams(ngrams_dict, doc_len):\n",
    "    for ngram in ngrams_dict:\n",
    "        ngrams_dict[ngram] = ngrams_dict[ngram] / float(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7ca14d-aa0c-414d-a8ad-c0b88d63eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per dividere il dataset in training e test set\n",
    "def train_test_split(all_documents): \n",
    "    train_features_dict = [] # Lista dei dizionari di feature per il training\n",
    "    train_labels = []  # Lista delle etichette di training (M/F)\n",
    "    test_features_dict, test_labels = [], []\n",
    "\n",
    "    for document in all_documents:\n",
    "        if document.split == \"training\" and document.gender != \"UNKNOWN\":  # Usa direttamente document.split invece di estrarre dal path\n",
    "            train_features_dict.append(document.features)\n",
    "            train_labels.append(document.gender) # Usa gender come etichetta\n",
    "        \n",
    "        elif document.split == \"test\":\n",
    "            test_features_dict.append(document.features)\n",
    "            test_labels.append(document.gender) # Usa gender come etichetta\n",
    "\n",
    "    return train_features_dict, train_labels, test_features_dict, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba097ca-46bb-4a8e-864b-f148723e07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare i veri valori del genere dal file test_CH.gold\n",
    "def load_gold_labels(file_path):\n",
    "    gold_labels = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            doc_id, gender = line.strip().split()\n",
    "            gold_labels[int(doc_id)] = gender\n",
    "    return gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cee55bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Filtro gold] Test documents: 6000 -> 152\n"
     ]
    }
   ],
   "source": [
    "# --- Filter test documents to match gold labels ---\n",
    "gold_labels = load_gold_labels(\"../../data/dataset_originale/gold/test_TW.gold\")\n",
    "gold_test_ids = set(gold_labels.keys())\n",
    "\n",
    "initial_test = sum(doc.split == \"test\" for doc in all_documents)\n",
    "all_documents = [\n",
    "    doc for doc in all_documents\n",
    "    if doc.split != \"test\" or int(doc.doc_id) in gold_test_ids\n",
    "]\n",
    "final_test = sum(doc.split == \"test\" for doc in all_documents)\n",
    "print(f\"[Filtro gold] Test documents: {initial_test} -> {final_test}\")\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd161485-2a63-4296-99cb-8935b9740529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per filtrare le feature poco frequenti\n",
    "def filter_features(train_features_dict, min_occurrences):\n",
    "    features_counter = dict() # Conto il numero di documenti in cui appare ogni features\n",
    "    for document_features_dict in train_features_dict:\n",
    "        for feature in document_features_dict:\n",
    "            if feature in features_counter:\n",
    "                features_counter[feature] += 1\n",
    "            else:\n",
    "                features_counter[feature] = 1\n",
    "    \n",
    "    # per ogni user, togliamo le features che compaiono in meno di \"min_occurrences\" utenti\n",
    "    for document_features_dict in train_features_dict:\n",
    "        document_features = list(document_features_dict.keys())\n",
    "        for feature in document_features:\n",
    "            if features_counter[feature] < min_occurrences:\n",
    "                document_features_dict.pop(feature)\n",
    "\n",
    "    return train_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b042e9d-2a83-41e7-88c0-13195d72e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle configurazioni di n-grammi da testare\n",
    "ngram_types = ['word', 'lemma', 'pos', 'char']\n",
    "ngram_lengths = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9e69c7f-a8d5-46ac-a1f5-3435eb441a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili per memorizzare i risultati migliori\n",
    "best_accuracy = 0\n",
    "best_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74650bc6-790a-4dbd-af9b-686972ebc4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.7000 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.7050 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6733 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6775 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6933 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.70      0.67      0.69      3000\n",
      "           M       0.68      0.70      0.69      3000\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.69      0.69      0.69      6000\n",
      "weighted avg       0.69      0.69      0.69      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6442 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6317 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6408 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6125 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6242 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.63      0.63      0.63      3000\n",
      "           M       0.63      0.64      0.63      3000\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.63      0.63      0.63      6000\n",
      "weighted avg       0.63      0.63      0.63      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5667 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.5858 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5933 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5733 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6092 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.56      0.80      0.66      3000\n",
      "           M       0.65      0.37      0.47      3000\n",
      "\n",
      "    accuracy                           0.59      6000\n",
      "   macro avg       0.61      0.59      0.57      6000\n",
      "weighted avg       0.61      0.59      0.57      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.6675 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6933 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6342 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6633 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6775 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.67      0.65      0.66      3000\n",
      "           M       0.66      0.68      0.67      3000\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.67      0.67      0.67      6000\n",
      "weighted avg       0.67      0.67      0.67      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6592 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6392 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6617 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6308 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6258 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.65      0.62      0.64      3000\n",
      "           M       0.64      0.66      0.65      3000\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.64      0.64      0.64      6000\n",
      "weighted avg       0.64      0.64      0.64      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5658 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.5867 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5942 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5775 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.5792 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.56      0.73      0.63      3000\n",
      "           M       0.61      0.43      0.51      3000\n",
      "\n",
      "    accuracy                           0.58      6000\n",
      "   macro avg       0.59      0.58      0.57      6000\n",
      "weighted avg       0.59      0.58      0.57      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.5867 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.5908 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5825 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5742 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.5833 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.59      0.53      0.56      3000\n",
      "           M       0.58      0.64      0.60      3000\n",
      "\n",
      "    accuracy                           0.58      6000\n",
      "   macro avg       0.58      0.58      0.58      6000\n",
      "weighted avg       0.58      0.58      0.58      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.5967 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6208 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5925 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5742 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.5942 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.60      0.57      0.59      3000\n",
      "           M       0.59      0.62      0.60      3000\n",
      "\n",
      "    accuracy                           0.60      6000\n",
      "   macro avg       0.60      0.60      0.60      6000\n",
      "weighted avg       0.60      0.60      0.60      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5692 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.5700 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5792 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5750 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.5825 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.58      0.56      0.57      3000\n",
      "           M       0.57      0.59      0.58      3000\n",
      "\n",
      "    accuracy                           0.58      6000\n",
      "   macro avg       0.58      0.58      0.58      6000\n",
      "weighted avg       0.58      0.58      0.58      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.6425 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6283 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6042 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6317 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.63      0.62      0.63      3000\n",
      "           M       0.63      0.64      0.63      3000\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.63      0.63      0.63      6000\n",
      "weighted avg       0.63      0.63      0.63      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6550 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6450 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6533 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6467 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6325 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.65      0.65      0.65      3000\n",
      "           M       0.65      0.64      0.64      3000\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.65      0.65      0.65      6000\n",
      "weighted avg       0.65      0.65      0.65      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.6967 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6667 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6842 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6683 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6583 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.68      0.67      0.67      3000\n",
      "           M       0.67      0.68      0.68      3000\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.67      0.67      0.67      6000\n",
      "weighted avg       0.67      0.67      0.67      6000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ciclo per testare diverse configurazioni di n-grammi\n",
    "for ngram_type in ngram_types:\n",
    "    for ngram_length in ngram_lengths:\n",
    "        print(f\"RISULTATI DELLE FOLD PER NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length}\")\n",
    "        \n",
    "        # Estrai le feature e normalizza\n",
    "        extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "        \n",
    "        # Dividi il dataset in training e test set\n",
    "        train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "        \n",
    "        # Filtra le feature poco frequenti\n",
    "        train_features_dict = filter_features(train_features_dict, 5)\n",
    "        \n",
    "        # Crea il vettore delle feature\n",
    "        vectorizer = DictVectorizer()\n",
    "        X_train = vectorizer.fit_transform(train_features_dict)\n",
    "        X_test = vectorizer.transform(test_features_dict)\n",
    "        \n",
    "        # Normalizza le feature\n",
    "        scaler = MaxAbsScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        y_train = np.asarray(train_labels)\n",
    "        splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        folds = list(splitter.split(X_train))\n",
    "        \n",
    "        # Variabili per raccogliere risultati complessivi\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        for i in range(len(folds)):\n",
    "            train_ids, test_ids = folds[i]\n",
    "            fold_X_train = X_train[train_ids]\n",
    "            fold_y_train = y_train[train_ids]\n",
    "            fold_X_test = X_train[test_ids]\n",
    "            fold_y_test = y_train[test_ids]\n",
    "            \n",
    "            # Normalizzazione dentro ogni fold (solo con i dati di training del fold)\n",
    "            scaler = MaxAbsScaler()\n",
    "            fold_X_train = scaler.fit_transform(fold_X_train)\n",
    "            fold_X_test = scaler.transform(fold_X_test)\n",
    "            \n",
    "            # Addestramento del modello SVM\n",
    "            kfold_svc = LinearSVC(dual=False)\n",
    "            kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "            fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "            \n",
    "            fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "            \n",
    "            # Baseline con Dummy Classifier\n",
    "            dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "            dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "            dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "            \n",
    "            all_y_true += fold_y_test.tolist()\n",
    "            all_y_pred += fold_y_pred.tolist()\n",
    "            \n",
    "            print(f\"Accuracy fold {i+1}: {fold_accuracy:.4f} \\t Baseline dummy: {dummy_score:.4f}\")\n",
    "        \n",
    "        # Calcola l'accuracy media su tutte le fold\n",
    "        average_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "        \n",
    "        # Report complessivo\n",
    "        print(f\"\\nREPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length} \")\n",
    "        print(classification_report(all_y_true, all_y_pred, zero_division=0))\n",
    "        print(\"\\n\")\n",
    "        # Aggiorna la migliore configurazione\n",
    "        if average_accuracy > best_accuracy:\n",
    "            best_accuracy = average_accuracy\n",
    "            best_config = (ngram_type, ngram_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c0a4e1e-12c3-49e1-ad80-d8bc21c06975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration: ('word', 1) with average accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "# Stampare la migliore configurazione\n",
    "print(f\"Best configuration: {best_config} with average accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3939a55c-81d6-4623-ab6b-85bfccde33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione sul test set con la migliore configurazione\n",
    "ngram_type, ngram_length = best_config\n",
    "extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "train_features_dict = filter_features(train_features_dict, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9348f9c4-9b42-4a3c-b5fe-055bd0be2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea il vettore delle feature\n",
    "vectorizer = DictVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_features_dict)\n",
    "X_test = vectorizer.transform(test_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8974eda0-1c29-402c-a8c1-e006c3166bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizza le feature\n",
    "scaler = MaxAbsScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "795ea6dc-6ae7-4ee3-90a4-3b64db48355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestra il modello SVM\n",
    "final_svc = LinearSVC(dual=False)\n",
    "final_svc.fit(X_train, train_labels)\n",
    "test_predictions = final_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4397b4d-f6f2-45d2-a739-675274fd4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i veri valori del genere\n",
    "gold_labels = load_gold_labels(\"../../data/dataset_originale/gold/test_TW.gold\")\n",
    "true_labels = [gold_labels[int(doc.doc_id)] for doc in all_documents if doc.split == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a76fb0f-53ed-4d29-b13c-2889b6ad8715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Valutazione finale sul test set ===\n",
      "Accuracy finale SVM: 0.4211\n",
      "Baseline Dummy Classifier: 0.4276\n"
     ]
    }
   ],
   "source": [
    "# Calcolo dell'accuratezza e confronto con baseline\n",
    "final_accuracy = accuracy_score(true_labels, test_predictions)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, train_labels)\n",
    "dummy_score = dummy_clf.score(X_test, true_labels)\n",
    "\n",
    "print(f\"=== Valutazione finale sul test set ===\")\n",
    "print(f\"Accuracy finale SVM: {final_accuracy:.4f}\")\n",
    "print(f\"Baseline Dummy Classifier: {dummy_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a767ddc3-3085-4513-a88f-e0fb9bb7141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Report di classificazione ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.42      0.94      0.58        65\n",
      "           M       0.43      0.03      0.06        87\n",
      "\n",
      "    accuracy                           0.42       152\n",
      "   macro avg       0.42      0.49      0.32       152\n",
      "weighted avg       0.43      0.42      0.28       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report di classificazione\n",
    "print(\"=== Report di classificazione ===\")\n",
    "print(classification_report(true_labels, test_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9f43bca-c577-4ed2-99a0-194bbb20f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1f61622de80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostra la matrice di confusione\n",
    "ConfusionMatrixDisplay.from_predictions(true_labels, test_predictions, xticks_rotation='vertical', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
