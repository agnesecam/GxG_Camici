{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badc9019-629f-4dd9-8fb4-cff6b892d29d",
   "metadata": {},
   "source": [
    "Dal task GxG Evalita 2018:\n",
    "\n",
    "\"Given a (collection of) text(s) from a specific genre, the gender of the author has to be predicted. The task is cast as a binary classification task, with gender represented as F (female) or M (male). Gender prediction will be done in two ways: \n",
    "\n",
    "1. **using a model which has been trained on the same genre**\n",
    "2. using a model which has been trained on anything but that genre.\"\n",
    "\n",
    "In questo file utilizzeremo un modello allenato sullo stesso genere su cui poi verrà testato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1da0c7a-2576-4f36-a412-3dc51a422ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazioni necessarie\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74cfdf7-ab7f-476d-88e6-8e5f1c7cca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i documenti e le annotazioni\n",
    "conllu_dir = \"../../data/profiling_output/twitter/linguistic_annotation/twitter/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850ddcf9-5548-4d82-9425-85b685e8b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle classi per la gestione dei documenti\n",
    "class Document:\n",
    "    \"\"\"Classe per rappresentare un documento con le sue frasi e metadati.\"\"\"\n",
    "    def __init__(self, document_path):\n",
    "        self.document_path = document_path\n",
    "        self._parse_doc_info(document_path)\n",
    "        self.sentences = []\n",
    "        self.features = None\n",
    "    \n",
    "    \"\"\" Estrae informazioni dal nome del file .conllu. \"\"\"\n",
    "    def _parse_doc_info(self, document_path):\n",
    "        document_path = document_path.split('/')[-1]\n",
    "        document_info = document_path.split('.')[0].split('#')\n",
    "        self.split = document_info[0]\n",
    "        self.doc_id = document_info[1]\n",
    "        self.genre = document_info[2]\n",
    "        self.gender = document_info[3]\n",
    "\n",
    "    \"\"\" Aggiunge un oggetto Sentence alla lista self.sentences. \"\"\"\n",
    "    def add_sentence(self, sentence):\n",
    "        self.sentences.append(sentence)\n",
    "    \n",
    "    # Per dopo\n",
    "    \"\"\" Conta il totale dei token nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_tokens(self):\n",
    "        num_words = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_words += sentence.get_num_tokens()\n",
    "        return num_words\n",
    "\n",
    "    \"\"\" Conta il totale dei caratteri nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_chars += sentence.get_num_chars()\n",
    "        return num_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298f3db4-3391-4dd5-8fc1-bca24990b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self):\n",
    "        self.tokens = [] # Inizializza una Sentence (frase) vuota con self.tokens = [] che conterrà i token della frase\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        self.tokens.append(token) # Aggiunge un oggetto tokens\n",
    "    \n",
    "    def get_words(self):\n",
    "        return [token.word for token in self.tokens] # Restituisce una lista delle parole nella frase\n",
    "    \n",
    "    def get_lemmas(self):\n",
    "        return [token.lemma for token in self.tokens] # Restituisce una lista dei lemmi della frase\n",
    "    \n",
    "    def get_pos(self):\n",
    "        return [token.pos for token in self.tokens] # Restituisce una lista dei PoS-tag della frase\n",
    "    \n",
    "    def get_num_tokens(self): \n",
    "        return len(self.tokens) # Restituisce il numero di token nella frase \n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for token in self.tokens:\n",
    "            num_chars += token.get_num_chars()\n",
    "        num_chars += self.get_num_tokens() - 1 # Contiamo anche gli spazi\n",
    "        return num_chars\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ' '.join([token.word for token in self.tokens])\n",
    "        # Converte l'oggetto Sentence in una stringa leggibile, restituendo la frase completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3896e861-16c0-4956-b070-e7e14997d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, word, lemma, pos):\n",
    "        self.word = word\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        return len(self.word) # Restituisce il numero di caratteri della parola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dce69b-6975-462f-b294-cb95e644a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare le frasi di un documento\n",
    "def load_document_sentences(document):\n",
    "    sentence = Sentence()\n",
    "    for line in open(document.document_path, 'r', encoding='MacRoman'):\n",
    "        if line[0].isdigit(): # se la riga inizia con un numero, che in .conllu indica un token (se la riga non inizia con un numero vuol dire che contiene info extra, come ad esempio # text = o # sent_id\n",
    "            splitted_line = line.strip().split('\\t') # rimuove spazi e divide la riga in colonne usando \\t\n",
    "            # esempio di riga divisa in colonne splitted_line = ['1', 'dobbiamo', 'dovere', 'AUX', 'VM', ...]\n",
    "            \n",
    "            if '-' not in splitted_line[0]:  # se l'id della parola non contiene un trattino\n",
    "                # Esclude le preposizioni articolate (multitoken: della, negli, sul) che in .conllu sono scritte con -.\n",
    "                \n",
    "                token = Token(splitted_line[1], splitted_line[2], splitted_line[3])\n",
    "                '''\n",
    "                Crea un oggetto Token(word, lemma, pos) con:\n",
    "                    splitted_line[1] → Parola (dobbiamo)\n",
    "                    splitted_line[2] → Lemma (dovere) \n",
    "                    splitted_line[3] → PoS (parte del discorso) (AUX)\n",
    "                '''\n",
    "                sentence.add_token(token) # aggiungo il token alla frase corrente\n",
    "        if line == '\\n': # se la riga è vuota significa che la frase è finita, perché nel file conllu le frasi sono separate da righe vuote\n",
    "            document.add_sentence(sentence)\n",
    "            sentence = Sentence() # crea un nuovo oggetto per iniziare una nuova frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade83184-3a79-4382-859c-2886d6b787c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i file .conllu\n",
    "all_documents = []\n",
    "for file_name in os.listdir(conllu_dir):\n",
    "    file_path = os.path.join(conllu_dir, file_name)\n",
    "    if os.path.isfile(file_path): \n",
    "        document = Document(file_path)\n",
    "        load_document_sentences(document)\n",
    "        all_documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f86863-0754-4530-939f-23b71a5924a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da una frase\n",
    "def extract_word_ngrams_from_sentence(word_ngrams, sentence, el, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    if el == 'word':\n",
    "        all_words = sentence.get_words()\n",
    "    elif el == 'lemma':\n",
    "        all_words = sentence.get_lemmas()\n",
    "    elif el == 'pos':\n",
    "        all_words = sentence.get_pos()\n",
    "    else:\n",
    "        raise Exception(f'Invalid element {el}')\n",
    "\n",
    "    # scorriamo la lista delle parole ed estraiamo gli n-grammi\n",
    "    for i in range(0, len(all_words) - n + 1):  # -n+1 serve per non uscire dal vettore\n",
    "        ngram_words = all_words[i: i + n]\n",
    "        ngram = f'{el.upper()}_{n}_' + '_'.join(ngram_words)\n",
    "        if ngram not in word_ngrams:\n",
    "            word_ngrams[ngram] = 1\n",
    "        else:\n",
    "            word_ngrams[ngram] += 1\n",
    "    \n",
    "    return word_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869a8592-421d-4293-87ae-74d7521491b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_char_ngrams_from_sentence(char_ngrams, sentence, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    all_words = sentence.get_words()\n",
    "\n",
    "    # creiamo una stringa che contenga tutte le parole separate tra spazi perché vogliamo scorrere i caratteri\n",
    "    all_words = ' '.join(all_words)\n",
    "    \n",
    "    # scorriamo la stringa ed estraiamo gli n-grammi di caratteri\n",
    "    for i in range(0, len(all_words) - n + 1):\n",
    "        ngram_chars = all_words[i:i + n]\n",
    "        ngram = f'CHAR_{n}_' + ngram_chars\n",
    "\n",
    "        if ngram not in char_ngrams:\n",
    "            char_ngrams[ngram] = 1\n",
    "        else:\n",
    "            char_ngrams[ngram] += 1\n",
    "    \n",
    "    return char_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd39197-5701-40ea-8d1a-49079bd91ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da tutti i documenti\n",
    "def extract_documents_ngrams_normalized(all_documents, ngram_type='word', ngram_length=1):\n",
    "    for document in all_documents:\n",
    "        ngrams_dict = dict()\n",
    "        for sentence in document.sentences:\n",
    "            if ngram_type == 'word':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'word', ngram_length)\n",
    "            elif ngram_type == 'lemma':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'lemma', ngram_length)\n",
    "            elif ngram_type == 'pos':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'pos', ngram_length)\n",
    "            elif ngram_type == 'char':\n",
    "                extract_char_ngrams_from_sentence(ngrams_dict, sentence, ngram_length)\n",
    "        \n",
    "        num_words = document.get_num_tokens()\n",
    "        num_chars = document.get_num_chars()\n",
    "        normalize_ngrams(ngrams_dict, num_words if ngram_type != 'char' else num_chars)\n",
    "        \n",
    "        document.features = ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f56b040-9f01-4343-871e-6ef10ecdb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per normalizzare le feature\n",
    "def normalize_ngrams(ngrams_dict, doc_len):\n",
    "    for ngram in ngrams_dict:\n",
    "        ngrams_dict[ngram] = ngrams_dict[ngram] / float(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7ca14d-aa0c-414d-a8ad-c0b88d63eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per dividere il dataset in training e test set\n",
    "def train_test_split(all_documents): \n",
    "    train_features_dict = [] # Lista dei dizionari di feature per il training\n",
    "    train_labels = []  # Lista delle etichette di training (M/F)\n",
    "    test_features_dict, test_labels = [], []\n",
    "\n",
    "    for document in all_documents:\n",
    "        if document.split == \"training\" and document.gender != \"UNKNOWN\":  # Usa direttamente document.split invece di estrarre dal path\n",
    "            train_features_dict.append(document.features)\n",
    "            train_labels.append(document.gender) # Usa gender come etichetta\n",
    "        \n",
    "        elif document.split == \"test\":\n",
    "            test_features_dict.append(document.features)\n",
    "            test_labels.append(document.gender) # Usa gender come etichetta\n",
    "\n",
    "    return train_features_dict, train_labels, test_features_dict, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba097ca-46bb-4a8e-864b-f148723e07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare i veri valori del genere dal file test_DI.gold\n",
    "def load_gold_labels(file_path):\n",
    "    gold_labels = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            doc_id, gender = line.strip().split()\n",
    "            gold_labels[int(doc_id)] = gender\n",
    "    return gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd161485-2a63-4296-99cb-8935b9740529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per filtrare le feature poco frequenti\n",
    "def filter_features(train_features_dict, min_occurrences):\n",
    "    features_counter = dict() # Conto il numero di documenti in cui appare ogni features\n",
    "    for document_features_dict in train_features_dict:\n",
    "        for feature in document_features_dict:\n",
    "            if feature in features_counter:\n",
    "                features_counter[feature] += 1\n",
    "            else:\n",
    "                features_counter[feature] = 1\n",
    "    \n",
    "    # per ogni user, togliamo le features che compaiono in meno di \"min_occurrences\" utenti\n",
    "    for document_features_dict in train_features_dict:\n",
    "        document_features = list(document_features_dict.keys())\n",
    "        for feature in document_features:\n",
    "            if features_counter[feature] < min_occurrences:\n",
    "                document_features_dict.pop(feature)\n",
    "\n",
    "    return train_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b042e9d-2a83-41e7-88c0-13195d72e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle configurazioni di n-grammi da testare\n",
    "ngram_types = ['word', 'lemma', 'pos', 'char']\n",
    "ngram_lengths = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e69c7f-a8d5-46ac-a1f5-3435eb441a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili per memorizzare i risultati migliori\n",
    "best_accuracy = 0\n",
    "best_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74650bc6-790a-4dbd-af9b-686972ebc4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.7000 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.7050 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6733 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6775 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6933 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.70      0.67      0.69      3000\n",
      "           M       0.68      0.70      0.69      3000\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.69      0.69      0.69      6000\n",
      "weighted avg       0.69      0.69      0.69      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6442 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6317 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6408 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6125 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6242 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.63      0.63      0.63      3000\n",
      "           M       0.63      0.64      0.63      3000\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.63      0.63      0.63      6000\n",
      "weighted avg       0.63      0.63      0.63      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5667 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.5858 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5933 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5733 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6092 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.56      0.80      0.66      3000\n",
      "           M       0.65      0.37      0.47      3000\n",
      "\n",
      "    accuracy                           0.59      6000\n",
      "   macro avg       0.61      0.59      0.57      6000\n",
      "weighted avg       0.61      0.59      0.57      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.6675 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6933 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6342 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6633 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6775 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.67      0.65      0.66      3000\n",
      "           M       0.66      0.68      0.67      3000\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.67      0.67      0.67      6000\n",
      "weighted avg       0.67      0.67      0.67      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6592 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6392 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6617 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6308 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6258 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.65      0.62      0.64      3000\n",
      "           M       0.64      0.66      0.65      3000\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.64      0.64      0.64      6000\n",
      "weighted avg       0.64      0.64      0.64      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5658 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.5867 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5942 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5775 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.5792 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.56      0.73      0.63      3000\n",
      "           M       0.61      0.43      0.51      3000\n",
      "\n",
      "    accuracy                           0.58      6000\n",
      "   macro avg       0.59      0.58      0.57      6000\n",
      "weighted avg       0.59      0.58      0.57      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.5867 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.5908 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5825 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5742 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.5833 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.59      0.53      0.56      3000\n",
      "           M       0.58      0.64      0.60      3000\n",
      "\n",
      "    accuracy                           0.58      6000\n",
      "   macro avg       0.58      0.58      0.58      6000\n",
      "weighted avg       0.58      0.58      0.58      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.5967 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6208 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5925 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5742 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.5942 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.60      0.57      0.59      3000\n",
      "           M       0.59      0.62      0.60      3000\n",
      "\n",
      "    accuracy                           0.60      6000\n",
      "   macro avg       0.60      0.60      0.60      6000\n",
      "weighted avg       0.60      0.60      0.60      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5692 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.5700 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.5792 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.5750 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.5825 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.58      0.56      0.57      3000\n",
      "           M       0.57      0.59      0.58      3000\n",
      "\n",
      "    accuracy                           0.58      6000\n",
      "   macro avg       0.58      0.58      0.58      6000\n",
      "weighted avg       0.58      0.58      0.58      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.6425 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6283 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6042 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6317 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.63      0.62      0.63      3000\n",
      "           M       0.63      0.64      0.63      3000\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.63      0.63      0.63      6000\n",
      "weighted avg       0.63      0.63      0.63      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6550 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6450 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6533 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6467 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6325 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.65      0.65      0.65      3000\n",
      "           M       0.65      0.64      0.64      3000\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.65      0.65      0.65      6000\n",
      "weighted avg       0.65      0.65      0.65      6000\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.6967 \t Baseline dummy: 0.4792\n",
      "Accuracy fold 2: 0.6667 \t Baseline dummy: 0.4775\n",
      "Accuracy fold 3: 0.6842 \t Baseline dummy: 0.4967\n",
      "Accuracy fold 4: 0.6683 \t Baseline dummy: 0.4800\n",
      "Accuracy fold 5: 0.6583 \t Baseline dummy: 0.4850\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.68      0.67      0.67      3000\n",
      "           M       0.67      0.68      0.68      3000\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.67      0.67      0.67      6000\n",
      "weighted avg       0.67      0.67      0.67      6000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ciclo per testare diverse configurazioni di n-grammi\n",
    "for ngram_type in ngram_types:\n",
    "    for ngram_length in ngram_lengths:\n",
    "        print(f\"RISULTATI DELLE FOLD PER NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length}\")\n",
    "        \n",
    "        # Estrai le feature e normalizza\n",
    "        extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "        \n",
    "        # Dividi il dataset in training e test set\n",
    "        train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "        \n",
    "        # Filtra le feature poco frequenti\n",
    "        train_features_dict = filter_features(train_features_dict, 5)\n",
    "        \n",
    "        # Crea il vettore delle feature\n",
    "        vectorizer = DictVectorizer()\n",
    "        X_train = vectorizer.fit_transform(train_features_dict)\n",
    "        X_test = vectorizer.transform(test_features_dict)\n",
    "        \n",
    "        # Normalizza le feature\n",
    "        scaler = MaxAbsScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        y_train = np.asarray(train_labels)\n",
    "        splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        folds = list(splitter.split(X_train))\n",
    "        \n",
    "        # Variabili per raccogliere risultati complessivi\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        for i in range(len(folds)):\n",
    "            train_ids, test_ids = folds[i]\n",
    "            fold_X_train = X_train[train_ids]\n",
    "            fold_y_train = y_train[train_ids]\n",
    "            fold_X_test = X_train[test_ids]\n",
    "            fold_y_test = y_train[test_ids]\n",
    "            \n",
    "            # Normalizzazione dentro ogni fold (solo con i dati di training del fold)\n",
    "            scaler = MaxAbsScaler()\n",
    "            fold_X_train = scaler.fit_transform(fold_X_train)\n",
    "            fold_X_test = scaler.transform(fold_X_test)\n",
    "            \n",
    "            # Addestramento del modello SVM\n",
    "            kfold_svc = LinearSVC(dual=False)\n",
    "            kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "            fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "            \n",
    "            fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "            \n",
    "            # Baseline con Dummy Classifier\n",
    "            dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "            dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "            dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "            \n",
    "            all_y_true += fold_y_test.tolist()\n",
    "            all_y_pred += fold_y_pred.tolist()\n",
    "            \n",
    "            print(f\"Accuracy fold {i+1}: {fold_accuracy:.4f} \\t Baseline dummy: {dummy_score:.4f}\")\n",
    "        \n",
    "        # Calcola l'accuracy media su tutte le fold\n",
    "        average_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "        \n",
    "        # Report complessivo\n",
    "        print(f\"\\nREPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length} \")\n",
    "        print(classification_report(all_y_true, all_y_pred, zero_division=0))\n",
    "        print(\"\\n\")\n",
    "        # Aggiorna la migliore configurazione\n",
    "        if average_accuracy > best_accuracy:\n",
    "            best_accuracy = average_accuracy\n",
    "            best_config = (ngram_type, ngram_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0a4e1e-12c3-49e1-ad80-d8bc21c06975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration: ('word', 1) with average accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "# Stampare la migliore configurazione\n",
    "print(f\"Best configuration: {best_config} with average accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3939a55c-81d6-4623-ab6b-85bfccde33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione sul test set con la migliore configurazione\n",
    "ngram_type, ngram_length = best_config\n",
    "extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "train_features_dict = filter_features(train_features_dict, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9348f9c4-9b42-4a3c-b5fe-055bd0be2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea il vettore delle feature\n",
    "vectorizer = DictVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_features_dict)\n",
    "X_test = vectorizer.transform(test_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8974eda0-1c29-402c-a8c1-e006c3166bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizza le feature\n",
    "scaler = MaxAbsScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "795ea6dc-6ae7-4ee3-90a4-3b64db48355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestra il modello SVM\n",
    "final_svc = LinearSVC(dual=False)\n",
    "final_svc.fit(X_train, train_labels)\n",
    "test_predictions = final_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12da26f7-1af3-4942-b3ef-beae8faeb539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunghezza true_labels: 6000\n",
      "Lunghezza predicted_labels: 6000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.49      0.58      0.53      3000\n",
      "           M       0.49      0.41      0.44      3000\n",
      "\n",
      "    accuracy                           0.49      6000\n",
      "   macro avg       0.49      0.49      0.49      6000\n",
      "weighted avg       0.49      0.49      0.49      6000\n",
      "\n",
      "Accuracy: 0.49116666666666664\n",
      "Confusion matrix:\n",
      " [[1732 1268]\n",
      " [1785 1215]]\n"
     ]
    }
   ],
   "source": [
    "# Carica direttamente in ordine le etichette gold dal file .gold\n",
    "with open(\"../../data/dataset_originale/gold/test_TW.gold\", encoding=\"utf-8\") as f:\n",
    "    true_labels = [line.strip().split(\"\\t\")[1] for line in f]\n",
    "\n",
    "# Usa direttamente le predizioni del modello\n",
    "predicted_labels = test_predictions\n",
    "\n",
    "# Verifica che il numero di etichette corrisponda\n",
    "print(\"Lunghezza true_labels:\", len(true_labels))\n",
    "print(\"Lunghezza predicted_labels:\", len(predicted_labels))\n",
    "\n",
    "# Calcola e stampa le metriche di valutazione\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, predicted_labels))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a76fb0f-53ed-4d29-b13c-2889b6ad8715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Valutazione finale sul test set ===\n",
      "Accuracy finale SVM: 0.4912\n",
      "Baseline Dummy Classifier: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Calcolo dell'accuratezza e confronto con baseline\n",
    "final_accuracy = accuracy_score(true_labels, test_predictions)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, train_labels)\n",
    "dummy_score = dummy_clf.score(X_test, true_labels)\n",
    "\n",
    "print(f\"=== Valutazione finale sul test set ===\")\n",
    "print(f\"Accuracy finale SVM: {final_accuracy:.4f}\")\n",
    "print(f\"Baseline Dummy Classifier: {dummy_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a767ddc3-3085-4513-a88f-e0fb9bb7141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Report di classificazione ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.49      0.58      0.53      3000\n",
      "           M       0.49      0.41      0.44      3000\n",
      "\n",
      "    accuracy                           0.49      6000\n",
      "   macro avg       0.49      0.49      0.49      6000\n",
      "weighted avg       0.49      0.49      0.49      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report di classificazione\n",
    "print(\"=== Report di classificazione ===\")\n",
    "print(classification_report(true_labels, test_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9f43bca-c577-4ed2-99a0-194bbb20f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x161402ea660>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostra la matrice di confusione\n",
    "ConfusionMatrixDisplay.from_predictions(true_labels, test_predictions, xticks_rotation='vertical', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
