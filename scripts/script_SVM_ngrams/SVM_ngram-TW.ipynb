{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8862ff3d-4fff-43ca-b33d-3ba7d65cafc5",
   "metadata": {},
   "source": [
    "# Fase 2 - SVM con ngrams (in-genre classification)\n",
    "\n",
    "Sviluppare un classificatore basato su SVM lineari che prende in input una rappresentazione del testo basata su n-grammi di caratteri, parole e part-of-speech. Riportare i seguenti risultati:\n",
    "- testare diverse rappresentazioni del testo che variano rispetto alla lunghezza degli ngrammi utilizzati e/o rispetto al tipo di informazione utilizzata all’interno degli ngrammi (forme, lemmi, caratteri, part-of-speech) e valutare i diversi sistemi con un\n",
    "processo di 5-fold cross validation condotto sul training set;\n",
    "- valutazione sul test set ufficiale del miglior sistema rispetto ai risultati ottenuti con il processo di 5-fold cross validation del punto sopra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc9019-629f-4dd9-8fb4-cff6b892d29d",
   "metadata": {},
   "source": [
    "Dal task GxG Evalita 2018:\n",
    "\n",
    "\"Given a (collection of) text(s) from a specific genre, the gender of the author has to be predicted. The task is cast as a binary classification task, with gender represented as F (female) or M (male). Gender prediction will be done in two ways: \n",
    "\n",
    "1. **using a model which has been trained on the same genre**\n",
    "2. using a model which has been trained on anything but that genre.\"\n",
    "\n",
    "In questo file utilizzeremo un modello allenato sullo stesso genere su cui poi verrà testato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1da0c7a-2576-4f36-a412-3dc51a422ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazioni necessarie\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74cfdf7-ab7f-476d-88e6-8e5f1c7cca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i documenti e le annotazioni\n",
    "conllu_dir = \"../../data/profiling_output/twitter/linguistic_annotation/twitter/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850ddcf9-5548-4d82-9425-85b685e8b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle classi per la gestione dei documenti\n",
    "class Document:\n",
    "    \"\"\"Classe per rappresentare un documento con le sue frasi e metadati.\"\"\"\n",
    "    def __init__(self, document_path):\n",
    "        self.document_path = document_path\n",
    "        self._parse_doc_info(document_path)\n",
    "        self.sentences = []\n",
    "        self.features = None\n",
    "    \n",
    "    \"\"\" Estrae informazioni dal nome del file .conllu. \"\"\"\n",
    "    def _parse_doc_info(self, document_path):\n",
    "        document_path = document_path.split('/')[-1]\n",
    "        document_info = document_path.split('.')[0].split('#')\n",
    "        self.split = document_info[0]\n",
    "        self.doc_id = document_info[1]\n",
    "        self.genre = document_info[2]\n",
    "        self.gender = document_info[3]\n",
    "\n",
    "    \"\"\" Aggiunge un oggetto Sentence alla lista self.sentences. \"\"\"\n",
    "    def add_sentence(self, sentence):\n",
    "        self.sentences.append(sentence)\n",
    "    \n",
    "    # Per dopo\n",
    "    \"\"\" Conta il totale dei token nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_tokens(self):\n",
    "        num_words = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_words += sentence.get_num_tokens()\n",
    "        return num_words\n",
    "\n",
    "    \"\"\" Conta il totale dei caratteri nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_chars += sentence.get_num_chars()\n",
    "        return num_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298f3db4-3391-4dd5-8fc1-bca24990b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self):\n",
    "        self.tokens = [] # Inizializza una Sentence (frase) vuota con self.tokens = [] che conterrà i token della frase\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        self.tokens.append(token) # Aggiunge un oggetto tokens\n",
    "    \n",
    "    def get_words(self):\n",
    "        return [token.word for token in self.tokens] # Restituisce una lista delle parole nella frase\n",
    "    \n",
    "    def get_lemmas(self):\n",
    "        return [token.lemma for token in self.tokens] # Restituisce una lista dei lemmi della frase\n",
    "    \n",
    "    def get_pos(self):\n",
    "        return [token.pos for token in self.tokens] # Restituisce una lista dei PoS-tag della frase\n",
    "    \n",
    "    def get_num_tokens(self): \n",
    "        return len(self.tokens) # Restituisce il numero di token nella frase \n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for token in self.tokens:\n",
    "            num_chars += token.get_num_chars()\n",
    "        num_chars += self.get_num_tokens() - 1 # Contiamo anche gli spazi\n",
    "        return num_chars\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ' '.join([token.word for token in self.tokens])\n",
    "        # Converte l'oggetto Sentence in una stringa leggibile, restituendo la frase completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3896e861-16c0-4956-b070-e7e14997d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, word, lemma, pos):\n",
    "        self.word = word\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        return len(self.word) # Restituisce il numero di caratteri della parola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dce69b-6975-462f-b294-cb95e644a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare le frasi di un documento\n",
    "def load_document_sentences(document):\n",
    "    sentence = Sentence()\n",
    "    for line in open(document.document_path, 'r', encoding='MacRoman'):\n",
    "        if line[0].isdigit(): # se la riga inizia con un numero, che in .conllu indica un token (se la riga non inizia con un numero vuol dire che contiene info extra, come ad esempio # text = o # sent_id\n",
    "            splitted_line = line.strip().split('\\t') # rimuove spazi e divide la riga in colonne usando \\t\n",
    "            # esempio di riga divisa in colonne splitted_line = ['1', 'dobbiamo', 'dovere', 'AUX', 'VM', ...]\n",
    "            \n",
    "            if '-' not in splitted_line[0]:  # se l'id della parola non contiene un trattino\n",
    "                # Esclude le preposizioni articolate (multitoken: della, negli, sul) che in .conllu sono scritte con -.\n",
    "                \n",
    "                token = Token(splitted_line[1], splitted_line[2], splitted_line[3])\n",
    "                '''\n",
    "                Crea un oggetto Token(word, lemma, pos) con:\n",
    "                    splitted_line[1] → Parola (dobbiamo)\n",
    "                    splitted_line[2] → Lemma (dovere) \n",
    "                    splitted_line[3] → PoS (parte del discorso) (AUX)\n",
    "                '''\n",
    "                sentence.add_token(token) # aggiungo il token alla frase corrente\n",
    "        if line == '\\n': # se la riga è vuota significa che la frase è finita, perché nel file conllu le frasi sono separate da righe vuote\n",
    "            document.add_sentence(sentence)\n",
    "            sentence = Sentence() # crea un nuovo oggetto per iniziare una nuova frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade83184-3a79-4382-859c-2886d6b787c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i file .conllu\n",
    "all_documents = []\n",
    "for file_name in os.listdir(conllu_dir):\n",
    "    file_path = os.path.join(conllu_dir, file_name)\n",
    "    if os.path.isfile(file_path): \n",
    "        document = Document(file_path)\n",
    "        load_document_sentences(document)\n",
    "        all_documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f86863-0754-4530-939f-23b71a5924a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da una frase\n",
    "def extract_word_ngrams_from_sentence(word_ngrams, sentence, el, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    if el == 'word':\n",
    "        all_words = sentence.get_words()\n",
    "    elif el == 'lemma':\n",
    "        all_words = sentence.get_lemmas()\n",
    "    elif el == 'pos':\n",
    "        all_words = sentence.get_pos()\n",
    "    else:\n",
    "        raise Exception(f'Invalid element {el}')\n",
    "\n",
    "    # scorriamo la lista delle parole ed estraiamo gli n-grammi\n",
    "    for i in range(0, len(all_words) - n + 1):  # -n+1 serve per non uscire dal vettore\n",
    "        ngram_words = all_words[i: i + n]\n",
    "        ngram = f'{el.upper()}_{n}_' + '_'.join(ngram_words)\n",
    "        if ngram not in word_ngrams:\n",
    "            word_ngrams[ngram] = 1\n",
    "        else:\n",
    "            word_ngrams[ngram] += 1\n",
    "    \n",
    "    return word_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869a8592-421d-4293-87ae-74d7521491b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_char_ngrams_from_sentence(char_ngrams, sentence, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    all_words = sentence.get_words()\n",
    "\n",
    "    # creiamo una stringa che contenga tutte le parole separate tra spazi perché vogliamo scorrere i caratteri\n",
    "    all_words = ' '.join(all_words)\n",
    "    \n",
    "    # scorriamo la stringa ed estraiamo gli n-grammi di caratteri\n",
    "    for i in range(0, len(all_words) - n + 1):\n",
    "        ngram_chars = all_words[i:i + n]\n",
    "        ngram = f'CHAR_{n}_' + ngram_chars\n",
    "\n",
    "        if ngram not in char_ngrams:\n",
    "            char_ngrams[ngram] = 1\n",
    "        else:\n",
    "            char_ngrams[ngram] += 1\n",
    "    \n",
    "    return char_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd39197-5701-40ea-8d1a-49079bd91ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da tutti i documenti\n",
    "def extract_documents_ngrams_normalized(all_documents, ngram_type='word', ngram_length=1):\n",
    "    for document in all_documents:\n",
    "        ngrams_dict = dict()\n",
    "        for sentence in document.sentences:\n",
    "            if ngram_type == 'word':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'word', ngram_length)\n",
    "            elif ngram_type == 'lemma':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'lemma', ngram_length)\n",
    "            elif ngram_type == 'pos':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'pos', ngram_length)\n",
    "            elif ngram_type == 'char':\n",
    "                extract_char_ngrams_from_sentence(ngrams_dict, sentence, ngram_length)\n",
    "        \n",
    "        num_words = document.get_num_tokens()\n",
    "        num_chars = document.get_num_chars()\n",
    "        normalize_ngrams(ngrams_dict, num_words if ngram_type != 'char' else num_chars)\n",
    "        \n",
    "        document.features = ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f56b040-9f01-4343-871e-6ef10ecdb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per normalizzare le feature\n",
    "def normalize_ngrams(ngrams_dict, doc_len):\n",
    "    for ngram in ngrams_dict:\n",
    "        ngrams_dict[ngram] = ngrams_dict[ngram] / float(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7ca14d-aa0c-414d-a8ad-c0b88d63eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per dividere il dataset in training e test set\n",
    "def train_test_split(all_documents): \n",
    "    train_features_dict = [] # Lista dei dizionari di feature per il training\n",
    "    train_labels = []  # Lista delle etichette di training (M/F)\n",
    "    test_features_dict, test_labels = [], []\n",
    "\n",
    "    for document in all_documents:\n",
    "        if document.split == \"training\" and document.gender != \"UNKNOWN\":  # Usa direttamente document.split invece di estrarre dal path\n",
    "            train_features_dict.append(document.features)\n",
    "            train_labels.append(document.gender) # Usa gender come etichetta\n",
    "        \n",
    "        elif document.split == \"test\":\n",
    "            test_features_dict.append(document.features)\n",
    "            test_labels.append(document.gender) # Usa gender come etichetta\n",
    "\n",
    "    return train_features_dict, train_labels, test_features_dict, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba097ca-46bb-4a8e-864b-f148723e07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare i veri valori del genere dal file test_CH.gold\n",
    "def load_gold_labels(file_path):\n",
    "    gold_labels = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            doc_id, gender = line.strip().split()\n",
    "            gold_labels[int(doc_id)] = gender\n",
    "    return gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd161485-2a63-4296-99cb-8935b9740529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per filtrare le feature poco frequenti\n",
    "def filter_features(train_features_dict, min_occurrences):\n",
    "    features_counter = dict() # Conto il numero di documenti in cui appare ogni features\n",
    "    for document_features_dict in train_features_dict:\n",
    "        for feature in document_features_dict:\n",
    "            if feature in features_counter:\n",
    "                features_counter[feature] += 1\n",
    "            else:\n",
    "                features_counter[feature] = 1\n",
    "    \n",
    "    # per ogni user, togliamo le features che compaiono in meno di \"min_occurrences\" utenti\n",
    "    for document_features_dict in train_features_dict:\n",
    "        document_features = list(document_features_dict.keys())\n",
    "        for feature in document_features:\n",
    "            if features_counter[feature] < min_occurrences:\n",
    "                document_features_dict.pop(feature)\n",
    "\n",
    "    return train_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b042e9d-2a83-41e7-88c0-13195d72e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle configurazioni di n-grammi da testare\n",
    "ngram_types = ['word', 'lemma', 'pos', 'char']\n",
    "ngram_lengths = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e69c7f-a8d5-46ac-a1f5-3435eb441a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili per memorizzare i risultati migliori\n",
    "best_accuracy = 0\n",
    "best_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74650bc6-790a-4dbd-af9b-686972ebc4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.5250 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.5500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.5250 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.4750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.4500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.50      0.57      0.54       100\n",
      "           M       0.51      0.44      0.47       100\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.51      0.51      0.50       200\n",
      "weighted avg       0.51      0.51      0.50       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.5000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.3000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.6000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.4500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.49      0.52      0.50       100\n",
      "           M       0.49      0.46      0.47       100\n",
      "\n",
      "    accuracy                           0.49       200\n",
      "   macro avg       0.49      0.49      0.49       200\n",
      "weighted avg       0.49      0.49      0.49       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5250 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.5250 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.4250 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.4000 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.51      0.47      0.49       100\n",
      "           M       0.50      0.54      0.52       100\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.51      0.51      0.50       200\n",
      "weighted avg       0.51      0.51      0.50       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.4000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.5500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.4500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.5750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.5750 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.51      0.57      0.54       100\n",
      "           M       0.51      0.45      0.48       100\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.51      0.51      0.51       200\n",
      "weighted avg       0.51      0.51      0.51       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.5750 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.5750 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.5000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.5750 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.57      0.63      0.60       100\n",
      "           M       0.58      0.52      0.55       100\n",
      "\n",
      "    accuracy                           0.57       200\n",
      "   macro avg       0.58      0.57      0.57       200\n",
      "weighted avg       0.58      0.57      0.57       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.4750 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.4250 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.5500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.3500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.46      0.46      0.46       100\n",
      "           M       0.46      0.46      0.46       100\n",
      "\n",
      "    accuracy                           0.46       200\n",
      "   macro avg       0.46      0.46      0.46       200\n",
      "weighted avg       0.46      0.46      0.46       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.5500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.6000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.5750 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.5000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.57      0.64      0.60       100\n",
      "           M       0.59      0.51      0.55       100\n",
      "\n",
      "    accuracy                           0.57       200\n",
      "   macro avg       0.58      0.57      0.57       200\n",
      "weighted avg       0.58      0.57      0.57       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.5500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.5500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.4750 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.5500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.5750 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.54      0.56      0.55       100\n",
      "           M       0.54      0.52      0.53       100\n",
      "\n",
      "    accuracy                           0.54       200\n",
      "   macro avg       0.54      0.54      0.54       200\n",
      "weighted avg       0.54      0.54      0.54       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.4250 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.5500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.5750 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.6000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.7500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.57      0.66      0.61       100\n",
      "           M       0.60      0.50      0.54       100\n",
      "\n",
      "    accuracy                           0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.4750 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.5500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.5500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.5000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.5000 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.51      0.54      0.53       100\n",
      "           M       0.52      0.49      0.50       100\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.52      0.52      0.51       200\n",
      "weighted avg       0.52      0.52      0.51       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.3250 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.6000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.5000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.5000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.5000 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.49      0.53      0.51       100\n",
      "           M       0.48      0.44      0.46       100\n",
      "\n",
      "    accuracy                           0.48       200\n",
      "   macro avg       0.48      0.48      0.48       200\n",
      "weighted avg       0.48      0.48      0.48       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5000 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 2: 0.5750 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 3: 0.4500 \t Baseline dummy: 0.4250\n",
      "Accuracy fold 4: 0.5500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.54      0.65      0.59       100\n",
      "           M       0.56      0.44      0.49       100\n",
      "\n",
      "    accuracy                           0.55       200\n",
      "   macro avg       0.55      0.55      0.54       200\n",
      "weighted avg       0.55      0.55      0.54       200\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ciclo per testare diverse configurazioni di n-grammi\n",
    "for ngram_type in ngram_types:\n",
    "    for ngram_length in ngram_lengths:\n",
    "        print(f\"RISULTATI DELLE FOLD PER NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length}\")\n",
    "        \n",
    "        # Estrai le feature e normalizza\n",
    "        extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "        \n",
    "        # Dividi il dataset in training e test set\n",
    "        train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "        \n",
    "        # Filtra le feature poco frequenti\n",
    "        train_features_dict = filter_features(train_features_dict, 5)\n",
    "        \n",
    "        # Crea il vettore delle feature\n",
    "        vectorizer = DictVectorizer()\n",
    "        X_train = vectorizer.fit_transform(train_features_dict)\n",
    "        X_test = vectorizer.transform(test_features_dict)\n",
    "        \n",
    "        # Normalizza le feature\n",
    "        scaler = MaxAbsScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        y_train = np.asarray(train_labels)\n",
    "        splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        folds = list(splitter.split(X_train))\n",
    "        \n",
    "        # Variabili per raccogliere risultati complessivi\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        for i in range(len(folds)):\n",
    "            train_ids, test_ids = folds[i]\n",
    "            fold_X_train = X_train[train_ids]\n",
    "            fold_y_train = y_train[train_ids]\n",
    "            fold_X_test = X_train[test_ids]\n",
    "            fold_y_test = y_train[test_ids]\n",
    "            \n",
    "            # Normalizzazione dentro ogni fold (solo con i dati di training del fold)\n",
    "            scaler = MaxAbsScaler()\n",
    "            fold_X_train = scaler.fit_transform(fold_X_train)\n",
    "            fold_X_test = scaler.transform(fold_X_test)\n",
    "            \n",
    "            # Addestramento del modello SVM\n",
    "            kfold_svc = LinearSVC(dual=False)\n",
    "            kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "            fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "            \n",
    "            fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "            \n",
    "            # Baseline con Dummy Classifier\n",
    "            dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "            dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "            dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "            \n",
    "            all_y_true += fold_y_test.tolist()\n",
    "            all_y_pred += fold_y_pred.tolist()\n",
    "            \n",
    "            print(f\"Accuracy fold {i+1}: {fold_accuracy:.4f} \\t Baseline dummy: {dummy_score:.4f}\")\n",
    "        \n",
    "        # Calcola l'accuracy media su tutte le fold\n",
    "        average_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "        \n",
    "        # Report complessivo\n",
    "        print(f\"\\nREPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length} \")\n",
    "        print(classification_report(all_y_true, all_y_pred, zero_division=0))\n",
    "        print(\"\\n\")\n",
    "        # Aggiorna la migliore configurazione\n",
    "        if average_accuracy > best_accuracy:\n",
    "            best_accuracy = average_accuracy\n",
    "            best_config = (ngram_type, ngram_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0a4e1e-12c3-49e1-ad80-d8bc21c06975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration: ('pos', 3) with average accuracy: 0.5800\n"
     ]
    }
   ],
   "source": [
    "# Stampare la migliore configurazione\n",
    "print(f\"Best configuration: {best_config} with average accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3939a55c-81d6-4623-ab6b-85bfccde33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione sul test set con la migliore configurazione\n",
    "ngram_type, ngram_length = best_config\n",
    "extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "train_features_dict = filter_features(train_features_dict, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9348f9c4-9b42-4a3c-b5fe-055bd0be2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea il vettore delle feature\n",
    "vectorizer = DictVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_features_dict)\n",
    "X_test = vectorizer.transform(test_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8974eda0-1c29-402c-a8c1-e006c3166bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizza le feature\n",
    "scaler = MaxAbsScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "795ea6dc-6ae7-4ee3-90a4-3b64db48355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestra il modello SVM\n",
    "final_svc = LinearSVC(dual=False)\n",
    "final_svc.fit(X_train, train_labels)\n",
    "test_predictions = final_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4397b4d-f6f2-45d2-a739-675274fd4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i veri valori del genere\n",
    "gold_labels = load_gold_labels(\"../../data/dataset_originale/gold/test_TW.gold\")\n",
    "true_labels = [gold_labels[int(doc.doc_id)] for doc in all_documents if doc.split == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a76fb0f-53ed-4d29-b13c-2889b6ad8715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Valutazione finale sul test set ===\n",
      "Accuracy finale SVM: 0.4774\n",
      "Baseline Dummy Classifier: 0.5025\n"
     ]
    }
   ],
   "source": [
    "# Calcolo dell'accuratezza e confronto con baseline\n",
    "final_accuracy = accuracy_score(true_labels, test_predictions)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, train_labels)\n",
    "dummy_score = dummy_clf.score(X_test, true_labels)\n",
    "\n",
    "print(f\"=== Valutazione finale sul test set ===\")\n",
    "print(f\"Accuracy finale SVM: {final_accuracy:.4f}\")\n",
    "print(f\"Baseline Dummy Classifier: {dummy_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a767ddc3-3085-4513-a88f-e0fb9bb7141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Report di classificazione ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.48      0.48      0.48       100\n",
      "           M       0.47      0.47      0.47        99\n",
      "\n",
      "    accuracy                           0.48       199\n",
      "   macro avg       0.48      0.48      0.48       199\n",
      "weighted avg       0.48      0.48      0.48       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report di classificazione\n",
    "print(\"=== Report di classificazione ===\")\n",
    "print(classification_report(true_labels, test_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9f43bca-c577-4ed2-99a0-194bbb20f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1eaec396120>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostra la matrice di confusione\n",
    "ConfusionMatrixDisplay.from_predictions(true_labels, test_predictions, xticks_rotation='vertical', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
