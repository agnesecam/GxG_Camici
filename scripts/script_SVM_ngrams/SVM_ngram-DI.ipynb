{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8862ff3d-4fff-43ca-b33d-3ba7d65cafc5",
   "metadata": {},
   "source": [
    "# Fase 2 - SVM con ngrams (in-genre classification)\n",
    "\n",
    "Sviluppare un classificatore basato su SVM lineari che prende in input una rappresentazione del testo basata su n-grammi di caratteri, parole e part-of-speech. Riportare i seguenti risultati:\n",
    "- testare diverse rappresentazioni del testo che variano rispetto alla lunghezza degli ngrammi utilizzati e/o rispetto al tipo di informazione utilizzata all’interno degli ngrammi (forme, lemmi, caratteri, part-of-speech) e valutare i diversi sistemi con un\n",
    "processo di 5-fold cross validation condotto sul training set;\n",
    "- valutazione sul test set ufficiale del miglior sistema rispetto ai risultati ottenuti con il processo di 5-fold cross validation del punto sopra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc9019-629f-4dd9-8fb4-cff6b892d29d",
   "metadata": {},
   "source": [
    "Dal task GxG Evalita 2018:\n",
    "\n",
    "\"Given a (collection of) text(s) from a specific genre, the gender of the author has to be predicted. The task is cast as a binary classification task, with gender represented as F (female) or M (male). Gender prediction will be done in two ways: \n",
    "\n",
    "1. **using a model which has been trained on the same genre**\n",
    "2. using a model which has been trained on anything but that genre.\"\n",
    "\n",
    "In questo file utilizzeremo un modello allenato sullo stesso genere su cui poi verrà testato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1da0c7a-2576-4f36-a412-3dc51a422ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazioni necessarie\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74cfdf7-ab7f-476d-88e6-8e5f1c7cca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i documenti e le annotazioni\n",
    "conllu_dir = \"../../data/profiling_output/diary/linguistic_annotation/diary/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850ddcf9-5548-4d82-9425-85b685e8b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle classi per la gestione dei documenti\n",
    "class Document:\n",
    "    \"\"\"Classe per rappresentare un documento con le sue frasi e metadati.\"\"\"\n",
    "    def __init__(self, document_path):\n",
    "        self.document_path = document_path\n",
    "        self._parse_doc_info(document_path)\n",
    "        self.sentences = []\n",
    "        self.features = None\n",
    "    \n",
    "    \"\"\" Estrae informazioni dal nome del file .conllu. \"\"\"\n",
    "    def _parse_doc_info(self, document_path):\n",
    "        document_path = document_path.split('/')[-1]\n",
    "        document_info = document_path.split('.')[0].split('#')\n",
    "        self.split = document_info[0]\n",
    "        self.doc_id = document_info[1]\n",
    "        self.genre = document_info[2]\n",
    "        self.gender = document_info[3]\n",
    "\n",
    "    \"\"\" Aggiunge un oggetto Sentence alla lista self.sentences. \"\"\"\n",
    "    def add_sentence(self, sentence):\n",
    "        self.sentences.append(sentence)\n",
    "    \n",
    "    # Per dopo\n",
    "    \"\"\" Conta il totale dei token nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_tokens(self):\n",
    "        num_words = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_words += sentence.get_num_tokens()\n",
    "        return num_words\n",
    "\n",
    "    \"\"\" Conta il totale dei caratteri nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_chars += sentence.get_num_chars()\n",
    "        return num_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298f3db4-3391-4dd5-8fc1-bca24990b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self):\n",
    "        self.tokens = [] # Inizializza una Sentence (frase) vuota con self.tokens = [] che conterrà i token della frase\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        self.tokens.append(token) # Aggiunge un oggetto tokens\n",
    "    \n",
    "    def get_words(self):\n",
    "        return [token.word for token in self.tokens] # Restituisce una lista delle parole nella frase\n",
    "    \n",
    "    def get_lemmas(self):\n",
    "        return [token.lemma for token in self.tokens] # Restituisce una lista dei lemmi della frase\n",
    "    \n",
    "    def get_pos(self):\n",
    "        return [token.pos for token in self.tokens] # Restituisce una lista dei PoS-tag della frase\n",
    "    \n",
    "    def get_num_tokens(self): \n",
    "        return len(self.tokens) # Restituisce il numero di token nella frase \n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for token in self.tokens:\n",
    "            num_chars += token.get_num_chars()\n",
    "        num_chars += self.get_num_tokens() - 1 # Contiamo anche gli spazi\n",
    "        return num_chars\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ' '.join([token.word for token in self.tokens])\n",
    "        # Converte l'oggetto Sentence in una stringa leggibile, restituendo la frase completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3896e861-16c0-4956-b070-e7e14997d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, word, lemma, pos):\n",
    "        self.word = word\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        return len(self.word) # Restituisce il numero di caratteri della parola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dce69b-6975-462f-b294-cb95e644a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare le frasi di un documento\n",
    "def load_document_sentences(document):\n",
    "    sentence = Sentence()\n",
    "    for line in open(document.document_path, 'r', encoding='MacRoman'):\n",
    "        if line[0].isdigit(): # se la riga inizia con un numero, che in .conllu indica un token (se la riga non inizia con un numero vuol dire che contiene info extra, come ad esempio # text = o # sent_id\n",
    "            splitted_line = line.strip().split('\\t') # rimuove spazi e divide la riga in colonne usando \\t\n",
    "            # esempio di riga divisa in colonne splitted_line = ['1', 'dobbiamo', 'dovere', 'AUX', 'VM', ...]\n",
    "            \n",
    "            if '-' not in splitted_line[0]:  # se l'id della parola non contiene un trattino\n",
    "                # Esclude le preposizioni articolate (multitoken: della, negli, sul) che in .conllu sono scritte con -.\n",
    "                \n",
    "                token = Token(splitted_line[1], splitted_line[2], splitted_line[3])\n",
    "                '''\n",
    "                Crea un oggetto Token(word, lemma, pos) con:\n",
    "                    splitted_line[1] → Parola (dobbiamo)\n",
    "                    splitted_line[2] → Lemma (dovere) \n",
    "                    splitted_line[3] → PoS (parte del discorso) (AUX)\n",
    "                '''\n",
    "                sentence.add_token(token) # aggiungo il token alla frase corrente\n",
    "        if line == '\\n': # se la riga è vuota significa che la frase è finita, perché nel file conllu le frasi sono separate da righe vuote\n",
    "            document.add_sentence(sentence)\n",
    "            sentence = Sentence() # crea un nuovo oggetto per iniziare una nuova frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade83184-3a79-4382-859c-2886d6b787c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i file .conllu\n",
    "all_documents = []\n",
    "for file_name in os.listdir(conllu_dir):\n",
    "    file_path = os.path.join(conllu_dir, file_name)\n",
    "    if os.path.isfile(file_path): \n",
    "        document = Document(file_path)\n",
    "        load_document_sentences(document)\n",
    "        all_documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f86863-0754-4530-939f-23b71a5924a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da una frase\n",
    "def extract_word_ngrams_from_sentence(word_ngrams, sentence, el, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    if el == 'word':\n",
    "        all_words = sentence.get_words()\n",
    "    elif el == 'lemma':\n",
    "        all_words = sentence.get_lemmas()\n",
    "    elif el == 'pos':\n",
    "        all_words = sentence.get_pos()\n",
    "    else:\n",
    "        raise Exception(f'Invalid element {el}')\n",
    "\n",
    "    # scorriamo la lista delle parole ed estraiamo gli n-grammi\n",
    "    for i in range(0, len(all_words) - n + 1):  # -n+1 serve per non uscire dal vettore\n",
    "        ngram_words = all_words[i: i + n]\n",
    "        ngram = f'{el.upper()}_{n}_' + '_'.join(ngram_words)\n",
    "        if ngram not in word_ngrams:\n",
    "            word_ngrams[ngram] = 1\n",
    "        else:\n",
    "            word_ngrams[ngram] += 1\n",
    "    \n",
    "    return word_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869a8592-421d-4293-87ae-74d7521491b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_char_ngrams_from_sentence(char_ngrams, sentence, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    all_words = sentence.get_words()\n",
    "\n",
    "    # creiamo una stringa che contenga tutte le parole separate tra spazi perché vogliamo scorrere i caratteri\n",
    "    all_words = ' '.join(all_words)\n",
    "    \n",
    "    # scorriamo la stringa ed estraiamo gli n-grammi di caratteri\n",
    "    for i in range(0, len(all_words) - n + 1):\n",
    "        ngram_chars = all_words[i:i + n]\n",
    "        ngram = f'CHAR_{n}_' + ngram_chars\n",
    "\n",
    "        if ngram not in char_ngrams:\n",
    "            char_ngrams[ngram] = 1\n",
    "        else:\n",
    "            char_ngrams[ngram] += 1\n",
    "    \n",
    "    return char_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd39197-5701-40ea-8d1a-49079bd91ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da tutti i documenti\n",
    "def extract_documents_ngrams_normalized(all_documents, ngram_type='word', ngram_length=1):\n",
    "    for document in all_documents:\n",
    "        ngrams_dict = dict()\n",
    "        for sentence in document.sentences:\n",
    "            if ngram_type == 'word':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'word', ngram_length)\n",
    "            elif ngram_type == 'lemma':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'lemma', ngram_length)\n",
    "            elif ngram_type == 'pos':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'pos', ngram_length)\n",
    "            elif ngram_type == 'char':\n",
    "                extract_char_ngrams_from_sentence(ngrams_dict, sentence, ngram_length)\n",
    "        \n",
    "        num_words = document.get_num_tokens()\n",
    "        num_chars = document.get_num_chars()\n",
    "        normalize_ngrams(ngrams_dict, num_words if ngram_type != 'char' else num_chars)\n",
    "        \n",
    "        document.features = ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f56b040-9f01-4343-871e-6ef10ecdb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per normalizzare le feature\n",
    "def normalize_ngrams(ngrams_dict, doc_len):\n",
    "    for ngram in ngrams_dict:\n",
    "        ngrams_dict[ngram] = ngrams_dict[ngram] / float(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7ca14d-aa0c-414d-a8ad-c0b88d63eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per dividere il dataset in training e test set\n",
    "def train_test_split(all_documents): \n",
    "    train_features_dict = [] # Lista dei dizionari di feature per il training\n",
    "    train_labels = []  # Lista delle etichette di training (M/F)\n",
    "    test_features_dict, test_labels = [], []\n",
    "\n",
    "    for document in all_documents:\n",
    "        if document.split == \"training\" and document.gender != \"UNKNOWN\":  # Usa direttamente document.split invece di estrarre dal path\n",
    "            train_features_dict.append(document.features)\n",
    "            train_labels.append(document.gender) # Usa gender come etichetta\n",
    "        \n",
    "        elif document.split == \"test\":\n",
    "            test_features_dict.append(document.features)\n",
    "            test_labels.append(document.gender) # Usa gender come etichetta\n",
    "\n",
    "    return train_features_dict, train_labels, test_features_dict, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba097ca-46bb-4a8e-864b-f148723e07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare i veri valori del genere dal file test_DI.gold\n",
    "def load_gold_labels(file_path):\n",
    "    gold_labels = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            doc_id, gender = line.strip().split()\n",
    "            gold_labels[int(doc_id)] = gender\n",
    "    return gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd161485-2a63-4296-99cb-8935b9740529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per filtrare le feature poco frequenti\n",
    "def filter_features(train_features_dict, min_occurrences):\n",
    "    features_counter = dict() # Conto il numero di documenti in cui appare ogni features\n",
    "    for document_features_dict in train_features_dict:\n",
    "        for feature in document_features_dict:\n",
    "            if feature in features_counter:\n",
    "                features_counter[feature] += 1\n",
    "            else:\n",
    "                features_counter[feature] = 1\n",
    "    \n",
    "    # per ogni user, togliamo le features che compaiono in meno di \"min_occurrences\" utenti\n",
    "    for document_features_dict in train_features_dict:\n",
    "        document_features = list(document_features_dict.keys())\n",
    "        for feature in document_features:\n",
    "            if features_counter[feature] < min_occurrences:\n",
    "                document_features_dict.pop(feature)\n",
    "\n",
    "    return train_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b042e9d-2a83-41e7-88c0-13195d72e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle configurazioni di n-grammi da testare\n",
    "ngram_types = ['word', 'lemma', 'pos', 'char']\n",
    "ngram_lengths = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e69c7f-a8d5-46ac-a1f5-3435eb441a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili per memorizzare i risultati migliori\n",
    "best_accuracy = 0\n",
    "best_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74650bc6-790a-4dbd-af9b-686972ebc4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.8250 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.7750 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.8750 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.7250 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.7500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.80      0.77      0.79       100\n",
      "           M       0.78      0.81      0.79       100\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.6250 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.8000 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6250 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6250 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.66      0.67      0.67       100\n",
      "           M       0.67      0.66      0.66       100\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.67      0.67      0.66       200\n",
      "weighted avg       0.67      0.67      0.66       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.6000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.5750 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.6250 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6250 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.59      0.67      0.63       100\n",
      "           M       0.62      0.54      0.58       100\n",
      "\n",
      "    accuracy                           0.60       200\n",
      "   macro avg       0.61      0.60      0.60       200\n",
      "weighted avg       0.61      0.60      0.60       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.8000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.7500 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.7250 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.8000 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.76      0.73      0.74       100\n",
      "           M       0.74      0.77      0.75       100\n",
      "\n",
      "    accuracy                           0.75       200\n",
      "   macro avg       0.75      0.75      0.75       200\n",
      "weighted avg       0.75      0.75      0.75       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.7250 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.6750 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.7500 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.7000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.8000 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.73      0.73      0.73       100\n",
      "           M       0.73      0.73      0.73       100\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.73      0.73      0.73       200\n",
      "weighted avg       0.73      0.73      0.73       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5250 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.5500 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.7000 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.62      0.63      0.62       100\n",
      "           M       0.62      0.61      0.62       100\n",
      "\n",
      "    accuracy                           0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.6000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.7000 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.5250 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.7000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.64      0.63      0.63       100\n",
      "           M       0.63      0.64      0.64       100\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.64      0.64      0.63       200\n",
      "weighted avg       0.64      0.64      0.63       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.6000 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.6250 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6750 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.64      0.65      0.64       100\n",
      "           M       0.64      0.63      0.64       100\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.6000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.7000 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.5750 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6750 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.66      0.54      0.59       100\n",
      "           M       0.61      0.72      0.66       100\n",
      "\n",
      "    accuracy                           0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.7750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.7000 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.7750 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.7250 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.72      0.73      0.73       100\n",
      "           M       0.73      0.72      0.72       100\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.73      0.72      0.72       200\n",
      "weighted avg       0.73      0.72      0.72       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6250 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.6500 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.6500 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.7500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6000 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.64      0.70      0.67       100\n",
      "           M       0.67      0.61      0.64       100\n",
      "\n",
      "    accuracy                           0.66       200\n",
      "   macro avg       0.66      0.66      0.65       200\n",
      "weighted avg       0.66      0.66      0.65       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.8750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.7500 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.9000 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.8000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.8250 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.83      0.83      0.83       100\n",
      "           M       0.83      0.83      0.83       100\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.83      0.83      0.83       200\n",
      "weighted avg       0.83      0.83      0.83       200\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ciclo per testare diverse configurazioni di n-grammi\n",
    "for ngram_type in ngram_types:\n",
    "    for ngram_length in ngram_lengths:\n",
    "        print(f\"RISULTATI DELLE FOLD PER NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length}\")\n",
    "        \n",
    "        # Estrai le feature e normalizza\n",
    "        extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "        \n",
    "        # Dividi il dataset in training e test set\n",
    "        train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "        \n",
    "        # Filtra le feature poco frequenti\n",
    "        train_features_dict = filter_features(train_features_dict, 5)\n",
    "        \n",
    "        # Crea il vettore delle feature\n",
    "        vectorizer = DictVectorizer()\n",
    "        X_train = vectorizer.fit_transform(train_features_dict)\n",
    "        X_test = vectorizer.transform(test_features_dict)\n",
    "        \n",
    "        # Normalizza le feature\n",
    "        scaler = MaxAbsScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        y_train = np.asarray(train_labels)\n",
    "        splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        folds = list(splitter.split(X_train))\n",
    "        \n",
    "        # Variabili per raccogliere risultati complessivi\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        for i in range(len(folds)):\n",
    "            train_ids, test_ids = folds[i]\n",
    "            fold_X_train = X_train[train_ids]\n",
    "            fold_y_train = y_train[train_ids]\n",
    "            fold_X_test = X_train[test_ids]\n",
    "            fold_y_test = y_train[test_ids]\n",
    "            \n",
    "            # Normalizzazione dentro ogni fold (solo con i dati di training del fold)\n",
    "            scaler = MaxAbsScaler()\n",
    "            fold_X_train = scaler.fit_transform(fold_X_train)\n",
    "            fold_X_test = scaler.transform(fold_X_test)\n",
    "            \n",
    "            # Addestramento del modello SVM\n",
    "            kfold_svc = LinearSVC(dual=False)\n",
    "            kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "            fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "            \n",
    "            fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "            \n",
    "            # Baseline con Dummy Classifier\n",
    "            dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "            dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "            dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "            \n",
    "            all_y_true += fold_y_test.tolist()\n",
    "            all_y_pred += fold_y_pred.tolist()\n",
    "            \n",
    "            print(f\"Accuracy fold {i+1}: {fold_accuracy:.4f} \\t Baseline dummy: {dummy_score:.4f}\")\n",
    "        \n",
    "        # Calcola l'accuracy media su tutte le fold\n",
    "        average_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "        \n",
    "        # Report complessivo\n",
    "        print(f\"\\nREPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length} \")\n",
    "        print(classification_report(all_y_true, all_y_pred, zero_division=0))\n",
    "        print(\"\\n\")\n",
    "        # Aggiorna la migliore configurazione\n",
    "        if average_accuracy > best_accuracy:\n",
    "            best_accuracy = average_accuracy\n",
    "            best_config = (ngram_type, ngram_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0a4e1e-12c3-49e1-ad80-d8bc21c06975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration: ('char', 3) with average accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "# Stampare la migliore configurazione\n",
    "print(f\"Best configuration: {best_config} with average accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3939a55c-81d6-4623-ab6b-85bfccde33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione sul test set con la migliore configurazione\n",
    "ngram_type, ngram_length = best_config\n",
    "extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "train_features_dict = filter_features(train_features_dict, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9348f9c4-9b42-4a3c-b5fe-055bd0be2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea il vettore delle feature\n",
    "vectorizer = DictVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_features_dict)\n",
    "X_test = vectorizer.transform(test_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8974eda0-1c29-402c-a8c1-e006c3166bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizza le feature\n",
    "scaler = MaxAbsScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "795ea6dc-6ae7-4ee3-90a4-3b64db48355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestra il modello SVM\n",
    "final_svc = LinearSVC(dual=False)\n",
    "final_svc.fit(X_train, train_labels)\n",
    "test_predictions = final_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4397b4d-f6f2-45d2-a739-675274fd4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i veri valori del genere\n",
    "gold_labels = load_gold_labels(\"../../data/dataset_originale/gold/test_DI.gold\")\n",
    "true_labels = [gold_labels[int(doc.doc_id)] for doc in all_documents if doc.split == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a76fb0f-53ed-4d29-b13c-2889b6ad8715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Valutazione finale sul test set ===\n",
      "Accuracy finale SVM: 0.5946\n",
      "Baseline Dummy Classifier: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Calcolo dell'accuratezza e confronto con baseline\n",
    "final_accuracy = accuracy_score(true_labels, test_predictions)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, train_labels)\n",
    "dummy_score = dummy_clf.score(X_test, true_labels)\n",
    "\n",
    "print(f\"=== Valutazione finale sul test set ===\")\n",
    "print(f\"Accuracy finale SVM: {final_accuracy:.4f}\")\n",
    "print(f\"Baseline Dummy Classifier: {dummy_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a767ddc3-3085-4513-a88f-e0fb9bb7141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Report di classificazione ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.64      0.43      0.52        37\n",
      "           M       0.57      0.76      0.65        37\n",
      "\n",
      "    accuracy                           0.59        74\n",
      "   macro avg       0.61      0.59      0.58        74\n",
      "weighted avg       0.61      0.59      0.58        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report di classificazione\n",
    "print(\"=== Report di classificazione ===\")\n",
    "print(classification_report(true_labels, test_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9f43bca-c577-4ed2-99a0-194bbb20f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x19199b4a120>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostra la matrice di confusione\n",
    "ConfusionMatrixDisplay.from_predictions(true_labels, test_predictions, xticks_rotation='vertical', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
