{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8862ff3d-4fff-43ca-b33d-3ba7d65cafc5",
   "metadata": {},
   "source": [
    "# Fase 2 - SVM con ngrams (in-genre classification)\n",
    "\n",
    "Sviluppare un classificatore basato su SVM lineari che prende in input una rappresentazione del testo basata su n-grammi di caratteri, parole e part-of-speech. Riportare i seguenti risultati:\n",
    "- testare diverse rappresentazioni del testo che variano rispetto alla lunghezza degli ngrammi utilizzati e/o rispetto al tipo di informazione utilizzata all’interno degli ngrammi (forme, lemmi, caratteri, part-of-speech) e valutare i diversi sistemi con un\n",
    "processo di 5-fold cross validation condotto sul training set;\n",
    "- valutazione sul test set ufficiale del miglior sistema rispetto ai risultati ottenuti con il processo di 5-fold cross validation del punto sopra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc9019-629f-4dd9-8fb4-cff6b892d29d",
   "metadata": {},
   "source": [
    "Dal task GxG Evalita 2018:\n",
    "\n",
    "\"Given a (collection of) text(s) from a specific genre, the gender of the author has to be predicted. The task is cast as a binary classification task, with gender represented as F (female) or M (male). Gender prediction will be done in two ways: \n",
    "\n",
    "1. **using a model which has been trained on the same genre**\n",
    "2. using a model which has been trained on anything but that genre.\"\n",
    "\n",
    "In questo file utilizzeremo un modello allenato sullo stesso genere su cui poi verrà testato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1da0c7a-2576-4f36-a412-3dc51a422ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazioni necessarie\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74cfdf7-ab7f-476d-88e6-8e5f1c7cca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i documenti e le annotazioni\n",
    "conllu_dir = \"../../data/profiling_output/journalism/linguistic_annotation/journalism/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850ddcf9-5548-4d82-9425-85b685e8b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle classi per la gestione dei documenti\n",
    "class Document:\n",
    "    \"\"\"Classe per rappresentare un documento con le sue frasi e metadati.\"\"\"\n",
    "    def __init__(self, document_path):\n",
    "        self.document_path = document_path\n",
    "        self._parse_doc_info(document_path)\n",
    "        self.sentences = []\n",
    "        self.features = None\n",
    "    \n",
    "    \"\"\" Estrae informazioni dal nome del file .conllu. \"\"\"\n",
    "    def _parse_doc_info(self, document_path):\n",
    "        document_path = document_path.split('/')[-1]\n",
    "        document_info = document_path.split('.')[0].split('#')\n",
    "        self.split = document_info[0]\n",
    "        self.doc_id = document_info[1]\n",
    "        self.genre = document_info[2]\n",
    "        self.gender = document_info[3]\n",
    "\n",
    "    \"\"\" Aggiunge un oggetto Sentence alla lista self.sentences. \"\"\"\n",
    "    def add_sentence(self, sentence):\n",
    "        self.sentences.append(sentence)\n",
    "    \n",
    "    # Per dopo\n",
    "    \"\"\" Conta il totale dei token nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_tokens(self):\n",
    "        num_words = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_words += sentence.get_num_tokens()\n",
    "        return num_words\n",
    "\n",
    "    \"\"\" Conta il totale dei caratteri nel documento, sommando quelli delle frasi. \"\"\"\n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_chars += sentence.get_num_chars()\n",
    "        return num_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298f3db4-3391-4dd5-8fc1-bca24990b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self):\n",
    "        self.tokens = [] # Inizializza una Sentence (frase) vuota con self.tokens = [] che conterrà i token della frase\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        self.tokens.append(token) # Aggiunge un oggetto tokens\n",
    "    \n",
    "    def get_words(self):\n",
    "        return [token.word for token in self.tokens] # Restituisce una lista delle parole nella frase\n",
    "    \n",
    "    def get_lemmas(self):\n",
    "        return [token.lemma for token in self.tokens] # Restituisce una lista dei lemmi della frase\n",
    "    \n",
    "    def get_pos(self):\n",
    "        return [token.pos for token in self.tokens] # Restituisce una lista dei PoS-tag della frase\n",
    "    \n",
    "    def get_num_tokens(self): \n",
    "        return len(self.tokens) # Restituisce il numero di token nella frase \n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for token in self.tokens:\n",
    "            num_chars += token.get_num_chars()\n",
    "        num_chars += self.get_num_tokens() - 1 # Contiamo anche gli spazi\n",
    "        return num_chars\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ' '.join([token.word for token in self.tokens])\n",
    "        # Converte l'oggetto Sentence in una stringa leggibile, restituendo la frase completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3896e861-16c0-4956-b070-e7e14997d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, word, lemma, pos):\n",
    "        self.word = word\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "    \n",
    "    def get_num_chars(self):\n",
    "        return len(self.word) # Restituisce il numero di caratteri della parola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dce69b-6975-462f-b294-cb95e644a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare le frasi di un documento\n",
    "def load_document_sentences(document):\n",
    "    sentence = Sentence()\n",
    "    for line in open(document.document_path, 'r', encoding='MacRoman'):\n",
    "        if line[0].isdigit(): # se la riga inizia con un numero, che in .conllu indica un token (se la riga non inizia con un numero vuol dire che contiene info extra, come ad esempio # text = o # sent_id\n",
    "            splitted_line = line.strip().split('\\t') # rimuove spazi e divide la riga in colonne usando \\t\n",
    "            # esempio di riga divisa in colonne splitted_line = ['1', 'dobbiamo', 'dovere', 'AUX', 'VM', ...]\n",
    "            \n",
    "            if '-' not in splitted_line[0]:  # se l'id della parola non contiene un trattino\n",
    "                # Esclude le preposizioni articolate (multitoken: della, negli, sul) che in .conllu sono scritte con -.\n",
    "                \n",
    "                token = Token(splitted_line[1], splitted_line[2], splitted_line[3])\n",
    "                '''\n",
    "                Crea un oggetto Token(word, lemma, pos) con:\n",
    "                    splitted_line[1] → Parola (dobbiamo)\n",
    "                    splitted_line[2] → Lemma (dovere) \n",
    "                    splitted_line[3] → PoS (parte del discorso) (AUX)\n",
    "                '''\n",
    "                sentence.add_token(token) # aggiungo il token alla frase corrente\n",
    "        if line == '\\n': # se la riga è vuota significa che la frase è finita, perché nel file conllu le frasi sono separate da righe vuote\n",
    "            document.add_sentence(sentence)\n",
    "            sentence = Sentence() # crea un nuovo oggetto per iniziare una nuova frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade83184-3a79-4382-859c-2886d6b787c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i file .conllu\n",
    "all_documents = []\n",
    "for file_name in os.listdir(conllu_dir):\n",
    "    file_path = os.path.join(conllu_dir, file_name)\n",
    "    if os.path.isfile(file_path): \n",
    "        document = Document(file_path)\n",
    "        load_document_sentences(document)\n",
    "        all_documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f86863-0754-4530-939f-23b71a5924a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da una frase\n",
    "def extract_word_ngrams_from_sentence(word_ngrams, sentence, el, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    if el == 'word':\n",
    "        all_words = sentence.get_words()\n",
    "    elif el == 'lemma':\n",
    "        all_words = sentence.get_lemmas()\n",
    "    elif el == 'pos':\n",
    "        all_words = sentence.get_pos()\n",
    "    else:\n",
    "        raise Exception(f'Invalid element {el}')\n",
    "\n",
    "    # scorriamo la lista delle parole ed estraiamo gli n-grammi\n",
    "    for i in range(0, len(all_words) - n + 1):  # -n+1 serve per non uscire dal vettore\n",
    "        ngram_words = all_words[i: i + n]\n",
    "        ngram = f'{el.upper()}_{n}_' + '_'.join(ngram_words)\n",
    "        if ngram not in word_ngrams:\n",
    "            word_ngrams[ngram] = 1\n",
    "        else:\n",
    "            word_ngrams[ngram] += 1\n",
    "    \n",
    "    return word_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869a8592-421d-4293-87ae-74d7521491b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_char_ngrams_from_sentence(char_ngrams, sentence, n):\n",
    "    # creiamo una lista con tutte le parole\n",
    "    all_words = sentence.get_words()\n",
    "\n",
    "    # creiamo una stringa che contenga tutte le parole separate tra spazi perché vogliamo scorrere i caratteri\n",
    "    all_words = ' '.join(all_words)\n",
    "    \n",
    "    # scorriamo la stringa ed estraiamo gli n-grammi di caratteri\n",
    "    for i in range(0, len(all_words) - n + 1):\n",
    "        ngram_chars = all_words[i:i + n]\n",
    "        ngram = f'CHAR_{n}_' + ngram_chars\n",
    "\n",
    "        if ngram not in char_ngrams:\n",
    "            char_ngrams[ngram] = 1\n",
    "        else:\n",
    "            char_ngrams[ngram] += 1\n",
    "    \n",
    "    return char_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd39197-5701-40ea-8d1a-49079bd91ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre n-grammi da tutti i documenti\n",
    "def extract_documents_ngrams_normalized(all_documents, ngram_type='word', ngram_length=1):\n",
    "    for document in all_documents:\n",
    "        ngrams_dict = dict()\n",
    "        for sentence in document.sentences:\n",
    "            if ngram_type == 'word':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'word', ngram_length)\n",
    "            elif ngram_type == 'lemma':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'lemma', ngram_length)\n",
    "            elif ngram_type == 'pos':\n",
    "                extract_word_ngrams_from_sentence(ngrams_dict, sentence, 'pos', ngram_length)\n",
    "            elif ngram_type == 'char':\n",
    "                extract_char_ngrams_from_sentence(ngrams_dict, sentence, ngram_length)\n",
    "        \n",
    "        num_words = document.get_num_tokens()\n",
    "        num_chars = document.get_num_chars()\n",
    "        normalize_ngrams(ngrams_dict, num_words if ngram_type != 'char' else num_chars)\n",
    "        \n",
    "        document.features = ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f56b040-9f01-4343-871e-6ef10ecdb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per normalizzare le feature\n",
    "def normalize_ngrams(ngrams_dict, doc_len):\n",
    "    for ngram in ngrams_dict:\n",
    "        ngrams_dict[ngram] = ngrams_dict[ngram] / float(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7ca14d-aa0c-414d-a8ad-c0b88d63eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per dividere il dataset in training e test set\n",
    "def train_test_split(all_documents): \n",
    "    train_features_dict = [] # Lista dei dizionari di feature per il training\n",
    "    train_labels = []  # Lista delle etichette di training (M/F)\n",
    "    test_features_dict, test_labels = [], []\n",
    "\n",
    "    for document in all_documents:\n",
    "        if document.split == \"training\" and document.gender != \"UNKNOWN\":  # Usa direttamente document.split invece di estrarre dal path\n",
    "            train_features_dict.append(document.features)\n",
    "            train_labels.append(document.gender) # Usa gender come etichetta\n",
    "        \n",
    "        elif document.split == \"test\":\n",
    "            test_features_dict.append(document.features)\n",
    "            test_labels.append(document.gender) # Usa gender come etichetta\n",
    "\n",
    "    return train_features_dict, train_labels, test_features_dict, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba097ca-46bb-4a8e-864b-f148723e07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare i veri valori del genere dal file test_DI.gold\n",
    "def load_gold_labels(file_path):\n",
    "    gold_labels = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            doc_id, gender = line.strip().split()\n",
    "            gold_labels[int(doc_id)] = gender\n",
    "    return gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd161485-2a63-4296-99cb-8935b9740529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per filtrare le feature poco frequenti\n",
    "def filter_features(train_features_dict, min_occurrences):\n",
    "    features_counter = dict() # Conto il numero di documenti in cui appare ogni features\n",
    "    for document_features_dict in train_features_dict:\n",
    "        for feature in document_features_dict:\n",
    "            if feature in features_counter:\n",
    "                features_counter[feature] += 1\n",
    "            else:\n",
    "                features_counter[feature] = 1\n",
    "    \n",
    "    # per ogni user, togliamo le features che compaiono in meno di \"min_occurrences\" utenti\n",
    "    for document_features_dict in train_features_dict:\n",
    "        document_features = list(document_features_dict.keys())\n",
    "        for feature in document_features:\n",
    "            if features_counter[feature] < min_occurrences:\n",
    "                document_features_dict.pop(feature)\n",
    "\n",
    "    return train_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b042e9d-2a83-41e7-88c0-13195d72e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle configurazioni di n-grammi da testare\n",
    "ngram_types = ['word', 'lemma', 'pos', 'char']\n",
    "ngram_lengths = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e69c7f-a8d5-46ac-a1f5-3435eb441a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili per memorizzare i risultati migliori\n",
    "best_accuracy = 0\n",
    "best_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74650bc6-790a-4dbd-af9b-686972ebc4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.6000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.6750 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.7250 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.8000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6750 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.70      0.68      0.69       100\n",
      "           M       0.69      0.71      0.70       100\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.70      0.70      0.69       200\n",
      "weighted avg       0.70      0.69      0.69       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.7500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.7500 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.6000 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.7000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.72      0.63      0.67       100\n",
      "           M       0.67      0.75      0.71       100\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO word DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.5500 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.5750 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.5500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO word DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.58      0.55      0.56       100\n",
      "           M       0.57      0.60      0.59       100\n",
      "\n",
      "    accuracy                           0.57       200\n",
      "   macro avg       0.58      0.57      0.57       200\n",
      "weighted avg       0.58      0.57      0.57       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.7750 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.7500 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.7750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.72      0.71      0.72       100\n",
      "           M       0.72      0.73      0.72       100\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.72      0.72      0.72       200\n",
      "weighted avg       0.72      0.72      0.72       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.7000 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.5500 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.65      0.63      0.64       100\n",
      "           M       0.64      0.66      0.65       100\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.65      0.65      0.64       200\n",
      "weighted avg       0.65      0.65      0.64       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO lemma DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.5500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.5500 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.5000 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.5750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.5250 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO lemma DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.54      0.55      0.54       100\n",
      "           M       0.54      0.53      0.54       100\n",
      "\n",
      "    accuracy                           0.54       200\n",
      "   macro avg       0.54      0.54      0.54       200\n",
      "weighted avg       0.54      0.54      0.54       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.6000 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.6500 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.7750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.4750 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.63      0.63      0.63       100\n",
      "           M       0.63      0.63      0.63       100\n",
      "\n",
      "    accuracy                           0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6250 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.5500 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.5250 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.5000 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.4250 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.52      0.54      0.53       100\n",
      "           M       0.53      0.51      0.52       100\n",
      "\n",
      "    accuracy                           0.53       200\n",
      "   macro avg       0.53      0.53      0.52       200\n",
      "weighted avg       0.53      0.53      0.52       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO pos DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.6250 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.6250 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.5500 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6500 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO pos DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.64      0.56      0.60       100\n",
      "           M       0.61      0.68      0.64       100\n",
      "\n",
      "    accuracy                           0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 1\n",
      "Accuracy fold 1: 0.7500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.6000 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.5750 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.5750 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.62      0.65      0.64       100\n",
      "           M       0.64      0.61      0.62       100\n",
      "\n",
      "    accuracy                           0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 2\n",
      "Accuracy fold 1: 0.6750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.6750 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.5750 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.7750 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.6250 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.67      0.64      0.66       100\n",
      "           M       0.66      0.69      0.67       100\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.67      0.67      0.66       200\n",
      "weighted avg       0.67      0.67      0.66       200\n",
      "\n",
      "\n",
      "\n",
      "RISULTATI DELLE FOLD PER NGRAMMI DI TIPO char DI LUNGHEZZA 3\n",
      "Accuracy fold 1: 0.6500 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 2: 0.5750 \t Baseline dummy: 0.4750\n",
      "Accuracy fold 3: 0.6500 \t Baseline dummy: 0.5000\n",
      "Accuracy fold 4: 0.7250 \t Baseline dummy: 0.4500\n",
      "Accuracy fold 5: 0.7250 \t Baseline dummy: 0.4750\n",
      "\n",
      "REPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO char DI LUNGHEZZA 3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.68      0.62      0.65       100\n",
      "           M       0.65      0.71      0.68       100\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.67      0.67      0.66       200\n",
      "weighted avg       0.67      0.67      0.66       200\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ciclo per testare diverse configurazioni di n-grammi\n",
    "for ngram_type in ngram_types:\n",
    "    for ngram_length in ngram_lengths:\n",
    "        print(f\"RISULTATI DELLE FOLD PER NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length}\")\n",
    "        \n",
    "        # Estrai le feature e normalizza\n",
    "        extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "        \n",
    "        # Dividi il dataset in training e test set\n",
    "        train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "        \n",
    "        # Filtra le feature poco frequenti\n",
    "        train_features_dict = filter_features(train_features_dict, 5)\n",
    "        \n",
    "        # Crea il vettore delle feature\n",
    "        vectorizer = DictVectorizer()\n",
    "        X_train = vectorizer.fit_transform(train_features_dict)\n",
    "        X_test = vectorizer.transform(test_features_dict)\n",
    "        \n",
    "        # Normalizza le feature\n",
    "        scaler = MaxAbsScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        y_train = np.asarray(train_labels)\n",
    "        splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        folds = list(splitter.split(X_train))\n",
    "        \n",
    "        # Variabili per raccogliere risultati complessivi\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        for i in range(len(folds)):\n",
    "            train_ids, test_ids = folds[i]\n",
    "            fold_X_train = X_train[train_ids]\n",
    "            fold_y_train = y_train[train_ids]\n",
    "            fold_X_test = X_train[test_ids]\n",
    "            fold_y_test = y_train[test_ids]\n",
    "            \n",
    "            # Normalizzazione dentro ogni fold (solo con i dati di training del fold)\n",
    "            scaler = MaxAbsScaler()\n",
    "            fold_X_train = scaler.fit_transform(fold_X_train)\n",
    "            fold_X_test = scaler.transform(fold_X_test)\n",
    "            \n",
    "            # Addestramento del modello SVM\n",
    "            kfold_svc = LinearSVC(dual=False)\n",
    "            kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "            fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "            \n",
    "            fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "            \n",
    "            # Baseline con Dummy Classifier\n",
    "            dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "            dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "            dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "            \n",
    "            all_y_true += fold_y_test.tolist()\n",
    "            all_y_pred += fold_y_pred.tolist()\n",
    "            \n",
    "            print(f\"Accuracy fold {i+1}: {fold_accuracy:.4f} \\t Baseline dummy: {dummy_score:.4f}\")\n",
    "        \n",
    "        # Calcola l'accuracy media su tutte le fold\n",
    "        average_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "        \n",
    "        # Report complessivo\n",
    "        print(f\"\\nREPORT FINALE DELLA CROSS VAL. CON NGRAMMI DI TIPO {ngram_type} DI LUNGHEZZA {ngram_length} \")\n",
    "        print(classification_report(all_y_true, all_y_pred, zero_division=0))\n",
    "        print(\"\\n\")\n",
    "        # Aggiorna la migliore configurazione\n",
    "        if average_accuracy > best_accuracy:\n",
    "            best_accuracy = average_accuracy\n",
    "            best_config = (ngram_type, ngram_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0a4e1e-12c3-49e1-ad80-d8bc21c06975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration: ('lemma', 1) with average accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "# Stampare la migliore configurazione\n",
    "print(f\"Best configuration: {best_config} with average accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3939a55c-81d6-4623-ab6b-85bfccde33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione sul test set con la migliore configurazione\n",
    "ngram_type, ngram_length = best_config\n",
    "extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_length)\n",
    "train_features_dict, train_labels, test_features_dict, test_labels = train_test_split(all_documents)\n",
    "train_features_dict = filter_features(train_features_dict, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9348f9c4-9b42-4a3c-b5fe-055bd0be2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea il vettore delle feature\n",
    "vectorizer = DictVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_features_dict)\n",
    "X_test = vectorizer.transform(test_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8974eda0-1c29-402c-a8c1-e006c3166bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizza le feature\n",
    "scaler = MaxAbsScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "795ea6dc-6ae7-4ee3-90a4-3b64db48355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestra il modello SVM\n",
    "final_svc = LinearSVC(dual=False)\n",
    "final_svc.fit(X_train, train_labels)\n",
    "test_predictions = final_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4397b4d-f6f2-45d2-a739-675274fd4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i veri valori del genere\n",
    "gold_labels = load_gold_labels(\"../../data/dataset_originale/gold/test_JO.gold\")\n",
    "true_labels = [gold_labels[int(doc.doc_id)] for doc in all_documents if doc.split == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a76fb0f-53ed-4d29-b13c-2889b6ad8715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Valutazione finale sul test set ===\n",
      "Accuracy finale SVM: 0.4800\n",
      "Baseline Dummy Classifier: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Calcolo dell'accuratezza e confronto con baseline\n",
    "final_accuracy = accuracy_score(true_labels, test_predictions)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, train_labels)\n",
    "dummy_score = dummy_clf.score(X_test, true_labels)\n",
    "\n",
    "print(f\"=== Valutazione finale sul test set ===\")\n",
    "print(f\"Accuracy finale SVM: {final_accuracy:.4f}\")\n",
    "print(f\"Baseline Dummy Classifier: {dummy_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a767ddc3-3085-4513-a88f-e0fb9bb7141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Report di classificazione ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.48      0.55      0.51       100\n",
      "           M       0.48      0.41      0.44       100\n",
      "\n",
      "    accuracy                           0.48       200\n",
      "   macro avg       0.48      0.48      0.48       200\n",
      "weighted avg       0.48      0.48      0.48       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report di classificazione\n",
    "print(\"=== Report di classificazione ===\")\n",
    "print(classification_report(true_labels, test_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9f43bca-c577-4ed2-99a0-194bbb20f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x14b6eb5a120>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGuCAYAAACJAZ8lAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMalJREFUeJzt3QtclGXa+PHrBhQUAU1RNFFDU/KAaW1urqfSTHNNq93eNTQzK21N0dLUtzUxa/GtXNvSzLVMt3LJNP2b21oe8pSHNU+vlZoHVAjNVVJEAw/w/9y3MS8jYDMMc+B5ft8+z4eZ53lm5saPec113SdVUFBQIAAAoMIL8ncDAABA+SCoAwBgEQR1AAAsgqAOAIBFENQBALAIgjoAABZBUAcAwCJCxCLy8/MlMzNTIiIiRCnl7+YAANykl005e/as1KtXT4KCvJdz5ubmyoULFzx+n8qVK0tYWJgEEssEdR3QY2Nj/d0MAICH0tPTpX79+l4L6FUiaopcOu/xe8XExEhaWlpABXbLBHWdoWu1B/xNgipX9XdzAK/4x4hO/m4C4DXncs7Kb3/TwvHvuTdc0Bn6pfMS2nygSHDlsr/R5Qty/Nt55v0I6l5QWHLXAZ2gDquqFhHp7yYAXueTLtSQMFEeBPUCFZhD0iwT1AEAcJn+3uDJl4cAHbpFUAcA2I8KunJ48voAFJitAgAAbiNTBwDYj1Ielt8Ds/5OUAcA2I+i/A4AAAIYmToAwH4U5XcAACwiyMMSemAWugOzVQAAwG1k6gAA+1GU3wEAsAbF6HcAABDAyNQBAPajKL8DAGANivI7AADWytSVB4cbkpOTzZayRY/4+HjH9ePHj8uAAQMkJiZGwsPDpW3btrJo0SK3fy0ydQAAfKBFixaycuVKx/OQkP8LwQ8//LCcPn1ali5dKrVq1ZL58+fLgw8+KF999ZW0adPG5c8gUwcA2Lf8rjw43KSDuM7ECw8dvAtt3LhRhg8fLrfddpvExcXJn/70J6levbps27bNrc8gqAMA7EcpD4P6lfJ7dna205GXl1fqR+7fv1/q1atngnZiYqIcPXrUca19+/by4YcfSlZWluTn50tqaqrk5uZKly5d3Pq1COoAAJRRbGysREVFOY6UlJQS72vXrp3MnTtXli9fLjNnzpS0tDTp2LGjnD171lxfsGCBXLx4UWrWrCmhoaEyZMgQWbx4sTRp0sSt9tCnDgCwnyB15fDk9SKSnp4ukZGRjtM6IJekZ8+ejscJCQkmyDds2NAE88GDB8uECRNMn7ruc9dl+SVLlpg+9fXr10urVq1cbhZBHQBgP6p8prTpgF40qLtK95c3bdpUDhw4IAcPHpTp06fL119/bQbTaa1btzYBfcaMGfLWW2+5/L6U3wEA8LGcnBwTzOvWrSvnz58354KCnENycHCw6V93B0EdAGA/yrfz1EePHi1r166Vw4cPm5Hu9913nwna/fr1M/PVdd+57kf/97//bYL91KlTZcWKFdK3b1+3PofyOwDAfpRvV5TLyMgwAfzUqVMSHR0tHTp0kM2bN5vH2qeffirjxo2T3r17myxeB/l58+bJPffc49bnENQBAPAyPUXtWm688cYyrSB3NYI6AMB+FBu6AABgDcqaG7oQ1AEA9qOsmakH5lcNAADgNjJ1AID9KMrvAABYg6L8DgAAAhiZOgDAhoI8LKEHZk5MUAcA2I+i/A4AAAIYmToAwKaZepBnrw9ABHUAgP0oa05pC8xWAQAAt5GpAwDsR1lzoBxBHQBgP8qa5XeCOgDAfpQ1M/XA/KoBAADcRqYOALAfRfkdAABrUJTfAQBAACNTBwDYjlLKHB68gQQigjoAwHaURYM65XcAACyCTB0AYD/q58OT1wcggjoAwHYU5XcAABDIyNQBALajLJqpE9QBALajCOoAAFiDsmhQp08dAACLIKgDAOw7pU15cLghOTnZUR0oPOLj453u2bRpk9x5550SHh4ukZGR0qlTJ/npp5/c+hzK7wAA21F+KL+3aNFCVq5c6XgeEhLiFNB79Ogh48ePlzfeeMNc27VrlwQFuZd7E9QBAPABHahjYmJKvDZq1CgZMWKEjBs3znGuWbNmbn8G5XcAgE13XlUeHFfeJzs72+nIy8sr9TP3798v9erVk7i4OElMTJSjR4+a8ydOnJAtW7ZI7dq1pX379lKnTh3p3LmzbNiwwe3fi6AOALAdpf/zJKj/3KkeGxsrUVFRjiMlJaXEz2vXrp3MnTtXli9fLjNnzpS0tDTp2LGjnD17Vg4dOuTod3/88cfNPW3btpWuXbuaLwLuoPwOAEAZpaenm0FthUJDQ0u8r2fPno7HCQkJJsg3bNhQFixYIDfddJM5P2TIEBk0aJB53KZNG1m1apXMmTOn1C8KJSGoAwBsR5XTQDkd0IsGdVdVr15dmjZtKgcOHDAj3rXmzZs73aODfWGJ3lWU3wEA9qN8O6Xtajk5OXLw4EGpW7euNGrUyPS179u3z+me7777zmTz7iBTBwDAy0aPHi29e/c2QTozM1MmTpwowcHB0q9fP1MxGDNmjDnXunVrufnmm2XevHmyd+9eWbhwoVufQ1AHANiP8qz8XuDmazMyMkwAP3XqlERHR0uHDh1k8+bN5rE2cuRIyc3NNVPbsrKyTHBfsWKFNG7c2K3PIagDAGxHeRjU3X1tamrqL96j56gXnadeFgR1AIDtKB8HdV9hoBwAABZBpg4AsB/l4Qj2wEzUCeoAAPtRlN8BAEAgI1MHANiOsmimTlAHANiOsmhQp/wOAIBFkKkDAGxHWTRTJ6gDAOxHWXNKG+V3AAAsgkwdAGA7ivI7AADWoAjqAABYg7JoUKdPHQAAiyBTBwDYj7Lm6HeCOgDAdhTldwAAEMjI1HFNI3rGS1LPm5zOHfzhrHR/aaV5/MHwDvLrG6Odrs/fkCYTFuz0aTuB8vD+x2tl1vufy+97tZcRg3uZc8MnvC07v0lzuq9P91/J6KF9/dRKlAdl0UydoI5f9F1mtgyYscHx/HJ+gdP11C/TZNqnexzPcy9e9mn7gPKwZ3+GLP18qzRuGFPsWu+7bpXBf+jmeB4WWsnHrUN5U+JhUA/QTvWAKr8/8sgjjm9PRY8DBw74u2m2dik/X06ezXMcP5674HT9p4uXna7n5F7yW1uBsjj/U5688NoCefbJvhJRrUqx62GVK0vNGhGOI7xqmF/aCVS4TL1Hjx7y7rvvOp2LjnYu78K3GkVXk42Te0jexXzZcThLXvnkGzn240+O6/feGit9bo2Vk9l5suqbYzJ9+T6ydVQo02Z/Irff0kxubd1E5i1cU+z65+t3yufrdsp11atJ+1/FyyO/v0PCQiv7pa0oH4ryu2+EhoZKTEzx8hf8Y9fhH+XZD7bJoRM5UjsyzPSxf5jUSXqmrJJzeZfkk20Z8n3WefnhTK7EXx8pz97bUuJqR8gf39ni76YDLlm54X/lu0OZ8reXnyzx+l0dE6ROdA2pdV2EHDx8XN567zNJ//6kvDQ20edtRTlSTGkLKHl5eeYolJ2d7df2WNXaPT84Hu/LzJadR36U9cl3yz1trpePNh+R1I2HHde/O5Yt/zmTK+8P7ygNaoXL0ZPn/NRqwDU/nDwtr7+zTP4y8VEJrVxyP/m93W9zPNb97TWvi5CRE+fI98dPyfUxNX3YWqACBvVly5ZJtWrVHM979uwpH330UbH7UlJSZNKkST5uHc7+dFHSTuRIw+jwEq/roK81JKijAth3MFN+PHNOHhs9w3Hucn6+7Pr2sHz8r82y6sNJEhzsPPSo+Y2x5mfGsSyCegWmKL/7xh133CEzZ850PA8PLzl4jB8/Xp5++mmnTD029sr/bPCeqpWDTRa+ZGtuidebXx9lfp7ILvk6EEhuTWgs86aNcDqXMn2RNKgfLYl9OxUL6Nr+tGPmpx4wh4pLEdR9QwfxJk2auNT3rg941/g+Lc3gt++zfpI6UWFmzvrlggL5ZHuGCe733lJf1nz7gxkRH18vUp67v5VsOXDSlOqBQFe1SqjENazjdC4srLJEVatqzusS+4p1u8wgusiIqqZP/Y13P5XWzRtJk0aM/anIlLpyePL6QBRwQR2BJaZ6FXlt4K+kenhlycq5INsOnpLf/WWteRwaEiztm9WWR7o0MRm8HhH/2c5MmfH5Pn83GygXISHB8tX/HpSPlm2U3LyLUrtWlHS+vYUM/F0XfzcNKBFBHdeUNG9rqdeOnf5JHnp9vU/bA3jbG5MfczyuU6u6TH/xcb+2B97M1JVHrw9EBHUAgP0oDwNzgAb1gFpRbu7cubJkyRJ/NwMAgHKVnJxcbLXU+Pj4YvcVFBSYWV/6elniIZk6AMB2lB9Gv7do0UJWrryyGZYWElI8BL/22msetYugDgCwHeWH0e86iF9rxdSdO3fK1KlT5auvvpK6detW/PI7AAAVSXZ2ttNRdKXTq+3fv1/q1asncXFxkpiYKEePHnVcO3/+vDz00EMyY8YMj5ZKJ6gDAGwnKEh5fGh60bOoqCjHoVc7LUm7du3MuLHly5ebBdbS0tKkY8eOcvbsWXN91KhR0r59e+nTp49HvxfldwCA7ahyKr+np6dLZGSk43xpi6LpwW+FEhISTJBv2LChLFiwwOxEunr1atmxY4d4iqAOAEAZ6YBeNKi7qnr16tK0aVM5cOCA7N69Ww4ePGjOFfXAAw+YbH7NmuLbAZeGoA4AsB3l57Xfc3JyTCAfMGCAPPjgg/LYY/+36JHWqlUrmTZtmvTu3dut9yWoAwBsR/l49Pvo0aNNgNYl98zMTJk4caIEBwdLv379TPm9pMFxDRo0kBtuuMGtzyGoAwBsR/k4U8/IyDAB/NSpUyaId+jQQTZv3mwelyeCOgAAXpaamurW/XplubIgqAMAbEexnzoAANagLLqfOovPAABgEWTqAADbUeJh+T1A914lqAMAbEdRfgcAAIGMTB0AYDuK0e8AAFiDovwOAAACGZk6AMB2FOV3AACsQVm0/E5QBwDYjrJopk6fOgAAFkGmDgCwH+VhCT0wE3WCOgDAfhTldwAAEMjI1AEAtqMY/Q4AgDUoyu8AACCQkakDAGxHUX4HAMAaFOV3AAAQyMjUAQC2oyyaqRPUAQC2o+hTBwDAGpRFM3X61AEAsAgydQCA7SjK7wAAWIOi/A4AAAIZmToAwHaUhyX0wMzTydQBADYUpJTHhzuSk5MdJf/CIz4+3lzLysqS4cOHS7NmzaRKlSrSoEEDGTFihJw5c8bt34tMHQAAH2jRooWsXLnS8Twk5EoIzszMNMerr74qzZs3lyNHjsjQoUPNuYULF7r1GQR1AIDtKD+MftdBPCYmptj5li1byqJFixzPGzduLC+99JL0799fLl265Aj+rqD8DgCwHXVVKbwsh5adne105OXllfqZ+/fvl3r16klcXJwkJibK0aNHS71Xl94jIyPdCugaQR0AYDtByvNDi42NlaioKMeRkpJS4ue1a9dO5s6dK8uXL5eZM2dKWlqadOzYUc6ePVvs3pMnT8rkyZPliSeecPv3ovwOAEAZpaenm4y6UGhoaIn39ezZ0/E4ISHBBPmGDRvKggULZPDgwY5rOtvv1auX6VvXg+vcRVAHANiP8nABmZ9fqgN60aDuqurVq0vTpk3lwIEDjnM6a+/Ro4dERETI4sWLpVKlSm6/L+V3AIBtB8opDw5P5OTkyMGDB6Vu3bqODL179+5SuXJlWbp0qYSFhZXpfQnqAAB42ejRo2Xt2rVy+PBh2bhxo9x3330SHBws/fr1cwT0c+fOyTvvvGOeHz9+3ByXL19263MovwMAbEf9/J8nr3dHRkaGCeCnTp2S6Oho6dChg2zevNk8XrNmjWzZssXc16RJE6fX6QF1jRo1cvlzCOoAANsJKjKCvayvd0dqamqp17p06SIFBQVSHii/AwBgEWTqAADbURbdepWgDgCwHeWHZWIDJqjr4fWuuvfeez1pDwAA8GZQ79u3r8vlCHeH3wMA4GtBZdg+9erXV9ignp+f7/2WAADgI8rO5ffS5ObmlnnVGwAA/EVZdKCc21PadHld7x5z/fXXS7Vq1eTQoUPm/IQJE8xKOAAAoIIEdb1xu94+7uWXXzZr1Bbd5P3tt98u7/YBAGC5td8DJqj//e9/l7/97W9mg3e9bm2h1q1by969e8u7fQAAeG2gXJAHhyWC+vfff19sbdrCwXQXL14sr3YBAABvB3W9cfv69euLnV+4cKG0adPG3bcDAMDnVDkclhj9/vzzz8vAgQNNxq6z848//lj27dtnyvLLli3zTisBAChHitHvV/Tp00c++eQTWblypYSHh5sgv2fPHnPurrvu8k4rAQCAd+apd+zYUVasWFGWlwIAYLutVwN+8ZmvvvrKZOiF/ey33HJLebYLAACvURYtv7sd1DMyMqRfv37y5ZdfSvXq1c2506dPS/v27c0m8PXr1/dGOwEAQHn3qT/22GNm6prO0rOyssyhH+tBc/oaAAAVgbLYwjNlytTXrl0rGzdulGbNmjnO6cdvvPGG6WsHACDQKcrvV8TGxpa4yIxeE75evXrl1S4AALwmyKID5dwuv7/yyisyfPhwM1CukH6clJQkr776anm3DwAAlGemXqNGDadSw7lz56Rdu3YSEnLl5ZcuXTKPH330Uenbt6+rnw0AgF8oO5ffX3vtNe+3BAAAH1EeLvUamCHdxaCul4UFAACBrcyLz2i5ubly4cIFp3ORkZGetgkAAK8K8nD7VMtsvar705966impXbu2Wftd97cXPQAAsPIcdRXAc9XdDurPPvusrF69WmbOnCmhoaHy9ttvy6RJk8x0Nr1TGwAAqCDld70bmw7eXbp0kUGDBpkFZ5o0aSINGzaUDz74QBITE73TUgAAyomy6Oh3tzN1vSxsXFyco/9cP9c6dOgg69atK/8WAgBQzhTl9yt0QE9LSzOP4+PjZcGCBY4MvnCDFwAAUAGCui6579q1yzweN26czJgxQ8LCwmTUqFEyZswYb7QRAACvjH4P8uBwR3JysqPkX3joxLjobLJhw4ZJzZo1pVq1avLAAw/IDz/84P0+dR28C3Xr1k327t0r27ZtM/3qCQkJbjcAAABfUx6W0Mvy2hYtWsjKlSsdzwtXZS2Mrf/85z/lo48+kqioKDPL7P777zfbnPtsnrqmB8jpAwCAikL5YaCcDuIxMTHFzp85c0beeecdmT9/vtx5553m3Lvvvis33XSTbN68WX7961+7/hmu3PT666+7/IYjRoxw+V4AACqy7Oxsp+d6qrc+SrJ//34z/Vt3Wd9+++2SkpIiDRo0MNVuvfuprn4X0qV5fW3Tpk3lH9SnTZvm8jcXfwf1H/+9VlRwZb+2AfCWlrH3+bsJgNdkZyufDigL8vD1hduRFzVx4kTTf341vQna3LlzpVmzZnLs2DGzvoueEv7111/L8ePHpXLlysUGm9epU8dcc4dLQb1wtDsAAFagyqn8np6e7rQ8emlZes+ePR2P9fgzHeR117WeQValSpUyt+NqnnxRAQDA1iIjI52O0oL61XRW3rRpUzlw4IDpZ9f7qJw+fdrpHj36vaQ++GshqAMAbEcpPa2t7Ieni8/k5OTIwYMHpW7dunLLLbdIpUqVZNWqVY7r+/btk6NHj5q+d5+OfgcAoKIJ+jk4e/J6d4wePVp69+5tSu6ZmZmm7z04OFj69etnprANHjxYnn76abnuuutMxj98+HAT0N0ZJKcR1AEA8LKMjAwTwE+dOiXR0dFmaXU9XU0/LhyQHhQUZBadycvLk7vvvlvefPNNtz+HoA4AsB3l43nqqamp17yup7npFVr14Yky9amvX79e+vfvb0oD33//vTn33nvvyYYNGzxqDAAAvhDkYZ+6J6V7b3I7qC9atMiUBfQQ/B07dpgyQeGKOH/+85+90UYAAOCNoP7iiy/KW2+9JbNnzzaj9Qr95je/ke3bt7v7dgAA+Jyy6Narbvep62H2nTp1KnZej967eo4dAACBKKgMO61d/XpLZOp6IryeLH813Z+u91oHACDQBZXDEYjcbtfjjz8uSUlJsmXLFjP6T8+3++CDD8wcvCeffNI7rQQAAOVffh83bpzk5+dL165d5fz586YUr5fF00FdT5YHACDQKT/spx6QQV1n588995yMGTPGlOH1UnfNmzeXatWqeaeFAACUsyDxsE9dAjOql3nxGb1NnA7mAACgggb1O+6445or6axevdrTNgEA4FWK8vsVN998s9Pzixcvys6dO81G7wMHDizPtgEAYIkNXQI2qOtF50uSnJxs+tcBAIB/lNtUO70W/Jw5c8rr7QAA8PJ+6qrMh2XK76XZtGmT2WUGAIBAp+hTv+L+++93el5QUCDHjh2Tr776SiZMmFCebQMAAN4M6nqN96L0pu7NmjWTF154Qbp37+7u2wEA4HNBDJQTuXz5sgwaNEhatWolNWrU8F6rAADwIvXzf568vsIPlAsODjbZOLuxAQCskKkHeXBYYvR7y5Yt5dChQ95pDQAA8F1Qf/HFF83mLcuWLTMD5LKzs50OAAACXZBFM3WX+9T1QLhnnnlG7rnnHvP83nvvdVouVo+C1891vzsAAIFMmbnmHvSpB+icNpeD+qRJk2To0KHyxRdfeLdFAADAu0FdZ+Ja586dy/ZJAAAEiCCmtAVuuQEAAHewopyING3a9BcDe1ZWlqdtAgAA3g7qul/96hXlAACoaIJ+3pjFk9dX+KD+hz/8QWrXru291gAA4ANBFu1Td3meOv3pAABYbPQ7AAAVnvJwsJuq4EE9Pz/fuy0BAMBHgkSZw5PXW2KZWAAArDKlTXlweGLKlCmmW3vkyJGOc8ePH5cBAwZITEyMhIeHS9u2bWXRokVuvS9BHQAAH9q6davMmjVLEhISnM4//PDDsm/fPlm6dKns3r1b7r//fnnwwQdlx44dLr83QR0AYDtBftrQJScnRxITE2X27NlSo0YNp2sbN26U4cOHy2233SZxcXHypz/9SapXry7btm1z/fcqW7MAAKj489SDPDi0q3cqzcvLu+bnDhs2THr16iXdunUrdq19+/by4YcfmkXc9Di21NRUyc3NlS5durj+e5XhzwIAAIhIbGysWZSt8EhJSSn1Xh2kt2/fXuo9CxYskIsXL0rNmjUlNDRUhgwZIosXL5YmTZp4Z/EZAACsQJXT2u/p6ekSGRnpOK+DcUn0fUlJSbJixQoJCwsr8Z4JEybI6dOnZeXKlVKrVi1ZsmSJ6VNfv369tGrVyqV2EdQBAPac0qY8n9KmA3rRoF4a3S9+4sQJM6K90OXLl2XdunUyffp0M0BO//z666+lRYsW5nrr1q1NQJ8xY4a89dZbLrWLoA4AgJd17drVjGgvatCgQRIfHy9jx46V8+fPm3NBQc694sHBwW6tE0NQBwDYjvLx1qsRERHSsmVLp3N6LrruP9fndV+67jvX/eivvvqqOa/L77pcv2zZMpc/h6AOALCdIA9Hipf3KPNKlSrJp59+KuPGjZPevXubqW86yM+bN0/uuecel9+HoA4AgB+sWbPG6fmNN97o9gpyVyOoAwBsRynl0e6jgbpzKUEdAGA7ysON1gIzpBPUAQA2FFRkVbiyvj4QsaIcAAAWQaYOALAlJdZDUAcA2I7y8Tx1X6H8DgCARZCpAwBsRzGlDQAAawgKsBXlykugtgsAALiJTB0AYDuK8jsAANagLLqiHOV3AAAsgkwdAGA7ivI7AADWEGTR0e8EdQCA7SiLZuqB+mUDAAC4iUwdAGA7yqKj3wnqAADbUWzoAgAAAhmZOgDAdoJEmcOT1wcigjoAwHYU5XcAABDIyNQBALajfv7Pk9cHIoI6AMB2FOV3AAAQyMjUAQC2ozwc/U75HQCAAKEsWn4nqAMAbEdZNKjTpw4AgEUQ1AEAtp3Spjz4zxNTpkwx27eOHDnS6fymTZvkzjvvlPDwcImMjJROnTrJTz/95PL7Un4HANhOkLpyePL6stq6davMmjVLEhISigX0Hj16yPjx4+WNN96QkJAQ2bVrlwQFuZ5/E9QBAPCRnJwcSUxMlNmzZ8uLL77odG3UqFEyYsQIGTdunONcs2bN3Hp/yu8AANtR5VR+z87Odjry8vKu+bnDhg2TXr16Sbdu3ZzOnzhxQrZs2SK1a9eW9u3bS506daRz586yYcMGt34vgjoAwLaj35UHhxYbGytRUVGOIyUlpdTPTE1Nle3bt5d4z6FDh8zP5ORkefzxx2X58uXStm1b6dq1q+zfv9/l34vyOwAAZZSenm4GtBUKDQ0t9b6kpCRZsWKFhIWFFbuen59vfg4ZMkQGDRpkHrdp00ZWrVolc+bMueaXhaII6gAA21EergpX+Eod0IsG9dJs27bNlNh19l3o8uXLsm7dOpk+fbrs27fPnGvevLnT62666SY5evSoy+0iqAMAbCfIx6PfdRl99+7dTud0Rh4fHy9jx46VuLg4qVevniO4F/ruu++kZ8+eLn8OQR0AAC+LiIiQli1bOp3Tc9Fr1qzpOD9mzBiZOHGitG7dWm6++WaZN2+e7N27VxYuXOjy5xDUcU1jH79Hxj1xj9O57w4fl3a/vzIVo9H1tWRy0n3y65vjpHKlEFm1aY+MffUj+U/WWT+1GCi7aXM/lxdmLJWhf+giKc/8zpyb+/EGWfjZV/K/+zLk7LlcObz6ZYmKqOrvpsKC+6mPHDlScnNzzdS2rKwsE9x1H3zjxo1dfg+COn7RnoOZ0nfYG47nly5dGdBRNayyfDx9mHy9/3vp8+SV6/89tJf84y9D5K5BU6WgoMBvbQbctf2bIzJ38ZfS4sbrnc7/lHtRut7e3Bw64MMaVACs/b5mzZpi5/Qc9aLz1N3l1yltjzzyiFkmb+jQoSXO5dPX9D3wr0uX8+XEqbOOI+vMOXO+Xes4aVC3pgyb9L58ezDTHH9Mfk/a3NRAOv2qqb+bDbgs53yePPH8XPnrf/eT6hFVnK49+dAdMuqR7vKrVo381j54a6CceHQEIr/PU9dz/PTcvaJr2+ryw/z586VBgwZ+bRuuiIuNlm8/fUl2LEmWv00eKPXr1DDnQyuHmGw878Ilx725Fy5Jfn6B/Lq16+UiwN/GvPyhdP9NS+nSLt7fTQEqdlDXw/t1YP/4448d5/RjHdD1HL3S6FV7rl7JB+Vv2zeHTSb++xEz5JkpH0rDejXl09mjpFrVUNm6+7Ccz70gycP7SJXQSqYcr/vXQ0KCJabWL0/xAALBos+/kl170+X5Yff6uynwoSBREqQ8OAI0V/d7UNceffRReffddx3P9UT7wsn3pdET8Yuu4qO/GKD8rdz4rfy/VTvkmwOZsnrzHvl90kyJiqgifbu1lVOnc+SRce9Ij44tJWPdVDnyxSvm2s49R022DgS6jOM/yvipi+Rvkx+RsNBK/m4OfEhZtPweEAPl+vfvb3alOXLkiHn+5ZdfmpJ8SYMICun7n376acdznakT2L0vO+cnOXD0hCnJa19s2Stt75sk10WFm753fX3v8j/L4c+3+bupwC/atfeomanRZcD/OM5dvpwvG3cclNkfrZMfvnxNgoMDIvcBKk5Qj46ONgvcz5071/TR6se1atW65mv0UnylLccH7wmvUlluuL6WfHjy307nCwfPdby1qUTXqCb/Wu+8yAIQiDr9qpl8+Y//djr31Avvy42N6kjSw3cR0K1MeZhuB2iqHhBBvbAE/9RTT5nHM2bM8Hdz8LMXku6T5et3S/qxLKkbHSXjnugll/PzZdFnVzLxh3r/Wr5LOy4nf8yR2xJukJSnfydv/uMLOXDkhL+bDvyiiPAwad6kntO5qlUqm8pT4fkfTmbLiVPZcij9pHmuu6IiqoZJ/ZgaUiMq3C/thjXnqVsqqOuN4S9cuGCmsd19993+bg5+dn3t6vL2i4PkuqiqJnBv2XXIzEHX/enajQ1rmwFGNSKrytHMLJn67mfy5vzV/m42UG7e/Xi9/M/sfzme93riNfNzxvP9zZdaIJAETFAPDg6WPXv2OB4jMAx+7v8GMJZk0vSl5gCsYtmskU7PdXVKH7AY5eECMoGZqAdOUNdc2ekGAABPKWt2qfs3qOuBcdeyZMkSn7UFAICKLqAydQAAfEJZM1UnqAMAbEcx+h0AAGtQAbBLmzewsgIAABZBpg4AsB1lzS51gjoAwIaUNaM65XcAACyCTB0AYDuK0e8AAFiDYvQ7AAAIZGTqAADbUdYcJ0dQBwDYkLJmVKf8DgCARZCpAwBsRzH6HQAAa1AWHf1OUAcA2I6yZpc6feoAAFgFmToAwH6UNVN1gjoAwHaURQfKUX4HAMDHpkyZIkopGTlyZLFrBQUF0rNnT3N9yZIlbr0vmToAwHaUH0e/b926VWbNmiUJCQklXn/ttddMQC8LMnUAgG271JUHR1nk5ORIYmKizJ49W2rUqFHs+s6dO2Xq1KkyZ86cMr0/QR0AgDLKzs52OvLy8q55/7Bhw6RXr17SrVu3YtfOnz8vDz30kMyYMUNiYmLK1B6COgDAflT5pOqxsbESFRXlOFJSUkr9yNTUVNm+fXup94waNUrat28vffr0KfOvRZ86AMB2VDmNfk9PT5fIyEjH+dDQ0BLv1/clJSXJihUrJCwsrNj1pUuXyurVq2XHjh3iCTJ1AADKSAf0okdpQX3btm1y4sQJadu2rYSEhJhj7dq18vrrr5vHOtgfPHhQqlev7riuPfDAA9KlSxeX20OmDgCwHeXj0e9du3aV3bt3O50bNGiQxMfHy9ixY6VWrVoyZMgQp+utWrWSadOmSe/evV3+HII6AMB2lI8XlIuIiJCWLVs6nQsPD5eaNWs6zpc0OK5BgwZyww03uPw5BHUAgP0olokFAADlZM2aNde8rleWcxdBHQBgO8qia78T1AEA9qM8GygXoDGdKW0AAFgFmToAwHaUNcfJEdQBADakrBnVKb8DAGARZOoAANtRjH4HAMAalI+XifUVyu8AAFgEmToAwHaUNcfJEdQBADakrBnVCeoAANtRFh0oR586AAAWQaYOALBn9V159vpARFAHANiOsmaXOuV3AACsgkwdAGA7yqKLzxDUAQA2pCxZgKf8DgCARZCpAwBsR1F+BwDAGpQli++U3wEAsAwydQCA7SjK7wAAWIOy6NrvBHUAgP0oa3aq06cOAIBFkKkDAGxHWTNRJ6gDAOxHWXSgHOV3AAAsgkwdAGA7itHvAABYhLJmpzrldwAAfGzKlCmilJKRI0ea51lZWTJ8+HBp1qyZVKlSRRo0aCAjRoyQM2fOuPW+ZOoAANtRfkzUt27dKrNmzZKEhATHuczMTHO8+uqr0rx5czly5IgMHTrUnFu4cKHL701QBwDYjiqn0e/Z2dlO50NDQ81RmpycHElMTJTZs2fLiy++6DjfsmVLWbRokeN548aN5aWXXpL+/fvLpUuXJCTEtXBN+R0AgDKKjY2VqKgox5GSknLN+4cNGya9evWSbt26/eJ769J7ZGSkywFdI1MHANiQ8nAE+5XXpqenm8Bb6FpZempqqmzfvt2U33/JyZMnZfLkyfLEE0+41SqCOgDAdlQ5ld91QC8a1Eujg39SUpKsWLFCwsLCrnmvLunrbF73rScnJ7vVLoI6AABetm3bNjlx4oS0bdvWce7y5cuybt06mT59uuTl5UlwcLCcPXtWevToIREREbJ48WKpVKmSW59DUAcAwMu6du0qu3fvdjo3aNAgiY+Pl7Fjx5qArjP0u+++25Twly5d+osZfUkI6gAA21E+XvtdZ956hHtR4eHhUrNmTXNeB/Tu3bvL+fPn5f333zfPC0fWR0dHm6DvCoI6AMB2VIAtE6sH0G3ZssU8btKkidO1tLQ0adSokUvvQ1AHAMAP1qxZ43jcpUsXKSgo8Pg9CeoAANtRFt16laAOALAdZc39XFhRDgAAqyBTBwDYj7Jmqk5QBwDYjgqw0e/lhfI7AAAWQaYOALAdxeh3AACsQVmzS52gDgCwIWXNqE6fOgAAFkGmDgCwHWXR0e8EdQCA7SgGygW2woXwCy5f8HdTAK8p3IoRsKKzP//9Lo+NTbz9/1Kg/r9omaB+9uxZ8/PCt/P83RTAa+rUnO3vJgA++fc8KirKK+9duXJliYmJkRtviPX4vfT76PcLJKrAF1+JfCA/P18yMzPNRvQqUOsiFqO/qcbGxkp6erpERkb6uzlAueLvt+/pcKQDer169SQoyHvjuHNzc+XCBc+rujqgh4WFSSCxTKau/wLUr1/f382wJf0PHv/owar4++1b3srQi9KBONCCcXlhShsAABZBUAcAwCII6iiz0NBQmThxovkJWA1/v1ERWWagHAAAdkemDgCARRDUAQCwCII6AAAWQVAHAMAiCOoAAFgEQR0uOXTokE82WQAAlB1T2uCS4OBgOXbsmNSuXds8/6//+i95/fXXpU6dOv5uGlAuHn30UZfumzNnjtfbApQVQR0ur61//PhxR1DXG+fs2rVL4uLi/N00oNz+jjds2FDatGlzzarU4sWLfdouwJYbugCAJ5588kn5xz/+IWlpaTJo0CDp37+/XHfddf5uFuAW+tThEr2d7dVb2rLFLaxkxowZpovp2WeflU8++cRsu/rggw/KZ599xngSVBiU3+FyabJnz56OdbD1P3p33nmnhIeHO9338ccf+6mFQPk6cuSIzJ07V/7+97/LpUuX5JtvvpFq1ar5u1nANVF+h0sGDhzo9FyXJgGrf5HV1Sid91y+fNnfzQFcQqYOAD/Ly8sz1SY9wn3Dhg3y29/+1vSv9+jRwwR5INCRqQOAiPzxj3+U1NRU05eup7fpQXO1atXyd7MAt5CpA8DP5fYGDRqYKW3XGgTKuBEEMjJ1ABCRhx9+mBkdqPDI1AEAsAhGfgAAYBEEdQAALIKgDgCARRDUAQCwCII6UI4eeeQR6du3r+N5ly5dZOTIkT5vx5o1a8xI7tOnT5d6j76+ZMkSl98zOTlZbr75Zo/adfjwYfO5O3fu9Oh9AJSMoA5bBNrCDWkqV64sTZo0kRdeeMGs5+1tek7z5MmTXbrXlUAMANfCPHXYgl7m89133zXLgH766acybNgwqVSpkowfP77YvRcuXDDBvzywdScAXyJThy3o3eViYmKkYcOGZt/sbt26ydKlS51K5i+99JLUq1dPmjVrZs6np6ebrTerV69ugnOfPn1M+biQ3uTj6aefNtdr1qxptuy8etmHq8vv+kvF2LFjzVKkuk26avDOO++Y973jjjvMPTVq1DAZu26Xlp+fLykpKXLDDTdIlSpVpHXr1rJw4UKnz9FfVJo2bWqu6/cp2k5X6Xbp96hatarExcXJhAkT5OLFi8XumzVrlmm/vk//+Zw5c8bp+ttvvy033XSThIWFSXx8vLz55ptutwVA2RDUYUs6+OmMvNCqVatk3759smLFClm2bJkJZnfffbdERETI+vXr5csvvzTbbuqMv/B1U6dONVtzFm7+kZWVJYsXL/7FVcv0muKvv/667NmzxwRI/b46SC5atMjco9uh9/X+61//ap7rgK63/3zrrbfM9p+jRo0yu+StXbvW8eXj/vvvl969e5u+6scee0zGjRvn9p+J/l317/Ptt9+az549e7ZMmzbN6Z4DBw7IggULzNa7y5cvlx07dpg10wt98MEH8vzzz5svSPr3+/Of/2y+HMybN8/t9gAoA72iHGBlAwcOLOjTp495nJ+fX7BixYqC0NDQgtGjRzuu16lTpyAvL8/xmvfee6+gWbNm5v5C+nqVKlUKPvvsM/O8bt26BS+//LLj+sWLFwvq16/v+Cytc+fOBUlJSebxvn37dBpvPr8kX3zxhbn+448/Os7l5uYWVK1atWDjxo1O9w4ePLigX79+5vH48eMLmjdv7nR97Nixxd7ravr64sWLS73+yiuvFNxyyy2O5xMnTiwIDg4uyMjIcJz717/+VRAUFFRw7Ngx87xx48YF8+fPd3qfyZMnF9x+++3mcVpamvncHTt2lPq5AMqOPnXYgs6+dUasM3Bdzn7ooYfMaO5CrVq1cupH37Vrl8lKdfZaVG5urhw8eNCUnHU23a5dO8e1kJAQufXWW4uV4AvpLDo4OFg6d+7scrt1G86fPy933XWX03ldLdAbj2g6Iy7aDu32228Xd3344YemgqB/v5ycHDOQMDIy0ukeveHJ9ddf7/Q5+s9TVxf0n5V+7eDBg+Xxxx933KPfJyoqyu32AHAfQR22oPuZZ86caQK37jfXAbio8PBwp+c6qN1yyy2mnHy16OjoMpf83aXbof3zn/90Cqaa7pMvL5s2bZLExESZNGmS6XbQQVhvQ6q7GNxtqy7bX/0lQ3+ZAeB9BHXYgg7aelCaq9q2bWsy19q1axfLVgvVrVtXtmzZIp06dXJkpNu2bTOvLYmuBuisVveF64F6VyusFOgBeIWaN29ugvfRo0dLzfD1oLTCQX+FNm/eLO7YuHGjGUT43HPPOc4dOXKk2H26HZmZmeaLUeHn6C1L9eDCOnXqmPOHDh0yXxAA+B4D5YAS6KBUq1YtM+JdD5RLS0sz88hHjBghGRkZ5p6kpCSZMmWKWcBl7969ZsDYteaYN2rUSAYOHCiPPvqoeU3he+qBZ5oOqnrUu+4q+M9//mMyX13SHj16tBkcpweb6fL29u3b5Y033nAMPhs6dKjs379fxowZY8rg8+fPNwPe3HHjjTeagK2zc/0Zugxf0qA/PaJd/w66e0L/ueg/Dz0CXs8s0HSmrwf26dd/9913snv3bjOV8C9/+Ytb7QFQNgR1oAR6uta6detMH7IeWa6zYd1XrPvUCzP3Z555RgYMGGCCnO5b1gH4vvvuu+b76i6A3/3ud+YLgJ7upfuez507Z67p8roOinrkus56n3rqKXNeL16jR5DrYKnboUfg63K8nuKm6TbqkfP6i4Ke7qZHyetR5+649957zRcH/Zl61TiduevPvJqudug/j3vuuUe6d+8uCQkJTlPW9Mh7PaVNB3JdmdDVBf0Fo7CtALyL/dQBALAIMnUAACyCoA4AgEUQ1AEAsAiCOgAAFkFQBwDAIgjqAABYBEEdAACLIKgDAGARBHUAACyCoA4AgEUQ1AEAEGv4/zIks3e1HHdeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostra la matrice di confusione\n",
    "ConfusionMatrixDisplay.from_predictions(true_labels, test_predictions, xticks_rotation='vertical', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
